[
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "gaussian_kde",
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "isExtraImport": true,
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "PCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "PCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "PCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "PCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "PCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "PCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "PCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "PCA",
        "importPath": "sklearn.decomposition",
        "description": "sklearn.decomposition",
        "isExtraImport": true,
        "detail": "sklearn.decomposition",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "DBSCAN",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "DBSCAN",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "DBSCAN",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "DBSCAN",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "DBSCAN",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "DBSCAN",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "DBSCAN",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "DBSCAN",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "umap",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "umap",
        "description": "umap",
        "detail": "umap",
        "documentation": {}
    },
    {
        "label": "measure",
        "importPath": "skimage",
        "description": "skimage",
        "isExtraImport": true,
        "detail": "skimage",
        "documentation": {}
    },
    {
        "label": "measure",
        "importPath": "skimage",
        "description": "skimage",
        "isExtraImport": true,
        "detail": "skimage",
        "documentation": {}
    },
    {
        "label": "measure",
        "importPath": "skimage",
        "description": "skimage",
        "isExtraImport": true,
        "detail": "skimage",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "KFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "balanced_accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "balanced_accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "balanced_accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "balanced_accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "balanced_accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "balanced_accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "balanced_accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "balanced_accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "balanced_accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "balanced_accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "balanced_accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "balanced_accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "balanced_accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "balanced_accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "balanced_accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "balanced_accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "isExtraImport": true,
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215634",
        "description": ".history.notebooks.randomsynapsetest_20241211215634",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75\n        points = np.concatenate([\n            np.random.normal(0.25, 0.1, n//2),\n            np.random.normal(0.75, 0.1, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211215634",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215634",
        "description": ".history.notebooks.randomsynapsetest_20241211215634",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.minimum(\n        np.diff(sorted_points),\n        np.diff(np.roll(sorted_points, 1))[1:]\n    )\n    # Calculate pairwise distances",
        "detail": ".history.notebooks.randomsynapsetest_20241211215634",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215634",
        "description": ".history.notebooks.randomsynapsetest_20241211215634",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as vertical lines\n    ax.vlines(points, 0, 1, color='black', alpha=0.5)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211215634",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215634",
        "description": ".history.notebooks.randomsynapsetest_20241211215634",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211215634",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215634",
        "description": ".history.notebooks.randomsynapsetest_20241211215634",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    experiments = [\n        ('uniform', 10, 'Uniform (N=10)'),\n        ('uniform', 50, 'Uniform (N=50)'),\n        ('two_bunches', 10, 'Two Bunches (N=10)'),\n        ('two_bunches', 50, 'Two Bunches (N=50)'),\n        ('three_clusters', 10, 'Three Clusters (N=10)'),\n        ('three_clusters', 50, 'Three Clusters (N=50)')\n    ]",
        "detail": ".history.notebooks.randomsynapsetest_20241211215634",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215635",
        "description": ".history.notebooks.randomsynapsetest_20241211215635",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75\n        points = np.concatenate([\n            np.random.normal(0.25, 0.1, n//2),\n            np.random.normal(0.75, 0.1, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211215635",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215635",
        "description": ".history.notebooks.randomsynapsetest_20241211215635",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.minimum(\n        np.diff(sorted_points),\n        np.diff(np.roll(sorted_points, 1))[1:]\n    )\n    # Calculate pairwise distances",
        "detail": ".history.notebooks.randomsynapsetest_20241211215635",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215635",
        "description": ".history.notebooks.randomsynapsetest_20241211215635",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as vertical lines\n    ax.vlines(points, 0, 1, color='black', alpha=0.5)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211215635",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215635",
        "description": ".history.notebooks.randomsynapsetest_20241211215635",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211215635",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215635",
        "description": ".history.notebooks.randomsynapsetest_20241211215635",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    experiments = [\n        ('uniform', 10, 'Uniform (N=10)'),\n        ('uniform', 50, 'Uniform (N=50)'),\n        ('two_bunches', 10, 'Two Bunches (N=10)'),\n        ('two_bunches', 50, 'Two Bunches (N=50)'),\n        ('three_clusters', 10, 'Three Clusters (N=10)'),\n        ('three_clusters', 50, 'Three Clusters (N=50)')\n    ]",
        "detail": ".history.notebooks.randomsynapsetest_20241211215635",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215709",
        "description": ".history.notebooks.randomsynapsetest_20241211215709",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75\n        points = np.concatenate([\n            np.random.normal(0.25, 0.1, n//2),\n            np.random.normal(0.75, 0.1, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211215709",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215709",
        "description": ".history.notebooks.randomsynapsetest_20241211215709",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211215709",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215709",
        "description": ".history.notebooks.randomsynapsetest_20241211215709",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as vertical lines\n    ax.vlines(points, 0, 1, color='black', alpha=0.5)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211215709",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215709",
        "description": ".history.notebooks.randomsynapsetest_20241211215709",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211215709",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215709",
        "description": ".history.notebooks.randomsynapsetest_20241211215709",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    experiments = [\n        ('uniform', 10, 'Uniform (N=10)'),\n        ('uniform', 50, 'Uniform (N=50)'),\n        ('two_bunches', 10, 'Two Bunches (N=10)'),\n        ('two_bunches', 50, 'Two Bunches (N=50)'),\n        ('three_clusters', 10, 'Three Clusters (N=10)'),\n        ('three_clusters', 50, 'Three Clusters (N=50)')\n    ]",
        "detail": ".history.notebooks.randomsynapsetest_20241211215709",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215711",
        "description": ".history.notebooks.randomsynapsetest_20241211215711",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75\n        points = np.concatenate([\n            np.random.normal(0.25, 0.1, n//2),\n            np.random.normal(0.75, 0.1, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211215711",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215711",
        "description": ".history.notebooks.randomsynapsetest_20241211215711",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211215711",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215711",
        "description": ".history.notebooks.randomsynapsetest_20241211215711",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as vertical lines\n    ax.vlines(points, 0, 1, color='black', alpha=0.5)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211215711",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215711",
        "description": ".history.notebooks.randomsynapsetest_20241211215711",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211215711",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215711",
        "description": ".history.notebooks.randomsynapsetest_20241211215711",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    experiments = [\n        ('uniform', 10, 'Uniform (N=10)'),\n        ('uniform', 50, 'Uniform (N=50)'),\n        ('two_bunches', 10, 'Two Bunches (N=10)'),\n        ('two_bunches', 50, 'Two Bunches (N=50)'),\n        ('three_clusters', 10, 'Three Clusters (N=10)'),\n        ('three_clusters', 50, 'Three Clusters (N=50)')\n    ]",
        "detail": ".history.notebooks.randomsynapsetest_20241211215711",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215817",
        "description": ".history.notebooks.randomsynapsetest_20241211215817",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75\n        points = np.concatenate([\n            np.random.normal(0.25, 0.1, n//2),\n            np.random.normal(0.75, 0.1, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211215817",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215817",
        "description": ".history.notebooks.randomsynapsetest_20241211215817",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211215817",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215817",
        "description": ".history.notebooks.randomsynapsetest_20241211215817",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211215817",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215817",
        "description": ".history.notebooks.randomsynapsetest_20241211215817",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211215817",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215817",
        "description": ".history.notebooks.randomsynapsetest_20241211215817",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    experiments = [\n        ('uniform', 10, 'Uniform (N=10)'),\n        ('uniform', 50, 'Uniform (N=50)'),\n        ('two_bunches', 10, 'Two Bunches (N=10)'),\n        ('two_bunches', 50, 'Two Bunches (N=50)'),\n        ('three_clusters', 10, 'Three Clusters (N=10)'),\n        ('three_clusters', 50, 'Three Clusters (N=50)')\n    ]",
        "detail": ".history.notebooks.randomsynapsetest_20241211215817",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215821",
        "description": ".history.notebooks.randomsynapsetest_20241211215821",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75\n        points = np.concatenate([\n            np.random.normal(0.25, 0.1, n//2),\n            np.random.normal(0.75, 0.1, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211215821",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215821",
        "description": ".history.notebooks.randomsynapsetest_20241211215821",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211215821",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215821",
        "description": ".history.notebooks.randomsynapsetest_20241211215821",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211215821",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215821",
        "description": ".history.notebooks.randomsynapsetest_20241211215821",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211215821",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215821",
        "description": ".history.notebooks.randomsynapsetest_20241211215821",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    experiments = [\n        ('uniform', 10, 'Uniform (N=10)'),\n        ('uniform', 50, 'Uniform (N=50)'),\n        ('two_bunches', 10, 'Two Bunches (N=10)'),\n        ('two_bunches', 50, 'Two Bunches (N=50)'),\n        ('three_clusters', 10, 'Three Clusters (N=10)'),\n        ('three_clusters', 50, 'Three Clusters (N=50)')\n    ]",
        "detail": ".history.notebooks.randomsynapsetest_20241211215821",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215955",
        "description": ".history.notebooks.randomsynapsetest_20241211215955",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75\n        points = np.concatenate([\n            np.random.normal(0.25, 0.1, n//2),\n            np.random.normal(0.75, 0.1, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211215955",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215955",
        "description": ".history.notebooks.randomsynapsetest_20241211215955",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211215955",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215955",
        "description": ".history.notebooks.randomsynapsetest_20241211215955",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211215955",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215955",
        "description": ".history.notebooks.randomsynapsetest_20241211215955",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211215955",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211215955",
        "description": ".history.notebooks.randomsynapsetest_20241211215955",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    experiments = [\n        ('uniform', 50, 'Uniform (N=50)'),\n        ('uniform', 100, 'Uniform (N=100)'),\n        ('two_bunches', 50, 'Two Bunches (N=50)'),\n        ('two_bunches', 100, 'Two Bunches (N=100)'),\n        ('three_clusters', 50, 'Three Clusters (N=50)'),\n        ('three_clusters', 100, 'Three Clusters (N=100)')\n    ]",
        "detail": ".history.notebooks.randomsynapsetest_20241211215955",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220207",
        "description": ".history.notebooks.randomsynapsetest_20241211220207",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.1 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.1 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211220207",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220207",
        "description": ".history.notebooks.randomsynapsetest_20241211220207",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211220207",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220207",
        "description": ".history.notebooks.randomsynapsetest_20241211220207",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211220207",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220207",
        "description": ".history.notebooks.randomsynapsetest_20241211220207",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211220207",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220207",
        "description": ".history.notebooks.randomsynapsetest_20241211220207",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    experiments = [\n        ('uniform', 10, 0.1, 'Uniform\\nShort stick (N=10)'),\n        ('uniform', 100, 1.0, 'Uniform\\nLong stick (N=100)'),\n        ('two_bunches', 10, 0.1, 'Two Bunches\\nShort stick (N=10)'),\n        ('two_bunches', 100, 1.0, 'Two Bunches\\nLong stick (N=100)'),\n        ('three_clusters', 10, 0.1, 'Three Clusters\\nShort stick (N=10)'),\n        ('three_clusters', 100, 1.0, 'Three Clusters\\nLong stick (N=100)')\n    ]",
        "detail": ".history.notebooks.randomsynapsetest_20241211220207",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220404",
        "description": ".history.notebooks.randomsynapsetest_20241211220404",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.1 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.1 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211220404",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220404",
        "description": ".history.notebooks.randomsynapsetest_20241211220404",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211220404",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220404",
        "description": ".history.notebooks.randomsynapsetest_20241211220404",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211220404",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220404",
        "description": ".history.notebooks.randomsynapsetest_20241211220404",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211220404",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220404",
        "description": ".history.notebooks.randomsynapsetest_20241211220404",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 10, 'Uniform\\n(N=10)'),\n        ('two_bunches', 10, 'Two Bunches\\n(N=10)'),\n        ('three_clusters', 10, 'Three Clusters\\n(N=10)'),\n        ('uniform', 100, 'Uniform\\n(N=100)'),\n        ('two_bunches', 100, 'Two Bunches\\n(N=100)'),\n        ('three_clusters', 100, 'Three Clusters\\n(N=100)')",
        "detail": ".history.notebooks.randomsynapsetest_20241211220404",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220407",
        "description": ".history.notebooks.randomsynapsetest_20241211220407",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.1 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.1 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211220407",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220407",
        "description": ".history.notebooks.randomsynapsetest_20241211220407",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211220407",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220407",
        "description": ".history.notebooks.randomsynapsetest_20241211220407",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211220407",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220407",
        "description": ".history.notebooks.randomsynapsetest_20241211220407",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211220407",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220407",
        "description": ".history.notebooks.randomsynapsetest_20241211220407",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 10, 'Uniform\\n(N=10)'),\n        ('two_bunches', 10, 'Two Bunches\\n(N=10)'),\n        ('three_clusters', 10, 'Three Clusters\\n(N=10)'),\n        ('uniform', 100, 'Uniform\\n(N=100)'),\n        ('two_bunches', 100, 'Two Bunches\\n(N=100)'),\n        ('three_clusters', 100, 'Three Clusters\\n(N=100)')",
        "detail": ".history.notebooks.randomsynapsetest_20241211220407",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220532",
        "description": ".history.notebooks.randomsynapsetest_20241211220532",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.1 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.1 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211220532",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220532",
        "description": ".history.notebooks.randomsynapsetest_20241211220532",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211220532",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220532",
        "description": ".history.notebooks.randomsynapsetest_20241211220532",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211220532",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220532",
        "description": ".history.notebooks.randomsynapsetest_20241211220532",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211220532",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220532",
        "description": ".history.notebooks.randomsynapsetest_20241211220532",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 10, 'Uniform\\n(N=10)'),\n        ('two_bunches', 10, 'Two Bunches\\n(N=10)'),\n        ('three_clusters', 10, 'Three Clusters\\n(N=10)'),\n        ('uniform', 100, 'Uniform\\n(N=100)'),\n        ('two_bunches', 100, 'Two Bunches\\n(N=100)'),\n        ('three_clusters', 100, 'Three Clusters\\n(N=100)')",
        "detail": ".history.notebooks.randomsynapsetest_20241211220532",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220809",
        "description": ".history.notebooks.randomsynapsetest_20241211220809",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.1 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.1 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211220809",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220809",
        "description": ".history.notebooks.randomsynapsetest_20241211220809",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211220809",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220809",
        "description": ".history.notebooks.randomsynapsetest_20241211220809",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211220809",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220809",
        "description": ".history.notebooks.randomsynapsetest_20241211220809",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211220809",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211220809",
        "description": ".history.notebooks.randomsynapsetest_20241211220809",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 10, 'Uniform\\nN=10'),\n        ('two_bunches', 10, 'Two Bunches\\nN=10'),\n        ('three_clusters', 10, 'Three Clusters\\nN=10'),\n        ('uniform', 100, 'Uniform\\nN=100'),\n        ('two_bunches', 100, 'Two Bunches\\nN=100'),\n        ('three_clusters', 100, 'Three Clusters\\nN=100')",
        "detail": ".history.notebooks.randomsynapsetest_20241211220809",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221038",
        "description": ".history.notebooks.randomsynapsetest_20241211221038",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.1 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.1 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211221038",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221038",
        "description": ".history.notebooks.randomsynapsetest_20241211221038",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211221038",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221038",
        "description": ".history.notebooks.randomsynapsetest_20241211221038",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211221038",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221038",
        "description": ".history.notebooks.randomsynapsetest_20241211221038",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211221038",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221038",
        "description": ".history.notebooks.randomsynapsetest_20241211221038",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 10, 'Uniform\\nN=10'),\n        ('uniform', 100, 'Uniform\\nN=100'),\n        ('two_bunches', 10, 'Two Bunches\\nN=10'),\n        ('two_bunches', 100, 'Two Bunches\\nN=100'),\n        ('three_clusters', 10, 'Three Clusters\\nN=10'),\n        ('three_clusters', 100, 'Three Clusters\\nN=100')",
        "detail": ".history.notebooks.randomsynapsetest_20241211221038",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221041",
        "description": ".history.notebooks.randomsynapsetest_20241211221041",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.1 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.1 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211221041",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221041",
        "description": ".history.notebooks.randomsynapsetest_20241211221041",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211221041",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221041",
        "description": ".history.notebooks.randomsynapsetest_20241211221041",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211221041",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221041",
        "description": ".history.notebooks.randomsynapsetest_20241211221041",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211221041",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221041",
        "description": ".history.notebooks.randomsynapsetest_20241211221041",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 10, 'Uniform\\nN=10'),\n        ('uniform', 100, 'Uniform\\nN=100'),\n        ('two_bunches', 10, 'Two Bunches\\nN=10'),\n        ('two_bunches', 100, 'Two Bunches\\nN=100'),\n        ('three_clusters', 10, 'Three Clusters\\nN=10'),\n        ('three_clusters', 100, 'Three Clusters\\nN=100')",
        "detail": ".history.notebooks.randomsynapsetest_20241211221041",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221105",
        "description": ".history.notebooks.randomsynapsetest_20241211221105",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.1 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.1 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211221105",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221105",
        "description": ".history.notebooks.randomsynapsetest_20241211221105",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211221105",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221105",
        "description": ".history.notebooks.randomsynapsetest_20241211221105",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211221105",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221105",
        "description": ".history.notebooks.randomsynapsetest_20241211221105",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211221105",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221105",
        "description": ".history.notebooks.randomsynapsetest_20241211221105",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 10, 'Uniform\\nN=10'),\n        ('uniform', 100, 'Uniform\\nN=100'),\n        ('two_bunches', 10, 'Two Bunches\\nN=10'),\n        ('two_bunches', 100, 'Two Bunches\\nN=100'),\n        ('three_clusters', 10, 'Three Clusters\\nN=10'),\n        ('three_clusters', 100, 'Three Clusters\\nN=100')",
        "detail": ".history.notebooks.randomsynapsetest_20241211221105",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221253",
        "description": ".history.notebooks.randomsynapsetest_20241211221253",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.05 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.05 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211221253",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221253",
        "description": ".history.notebooks.randomsynapsetest_20241211221253",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211221253",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221253",
        "description": ".history.notebooks.randomsynapsetest_20241211221253",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211221253",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221253",
        "description": ".history.notebooks.randomsynapsetest_20241211221253",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211221253",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221253",
        "description": ".history.notebooks.randomsynapsetest_20241211221253",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 10, 'Uniform\\nN=10'),\n        ('uniform', 100, 'Uniform\\nN=100'),\n        ('two_bunches', 10, 'Two Bunches\\nN=10'),\n        ('two_bunches', 100, 'Two Bunches\\nN=100'),\n        ('three_clusters', 10, 'Three Clusters\\nN=10'),\n        ('three_clusters', 100, 'Three Clusters\\nN=100')",
        "detail": ".history.notebooks.randomsynapsetest_20241211221253",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221914",
        "description": ".history.notebooks.randomsynapsetest_20241211221914",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.05 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.05 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211221914",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221914",
        "description": ".history.notebooks.randomsynapsetest_20241211221914",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211221914",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221914",
        "description": ".history.notebooks.randomsynapsetest_20241211221914",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211221914",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221914",
        "description": ".history.notebooks.randomsynapsetest_20241211221914",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211221914",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221914",
        "description": ".history.notebooks.randomsynapsetest_20241211221914",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 10, 'Uniform\\nN=10'),\n        ('uniform', 100, 'Uniform\\nN=100'),\n        ('two_bunches', 10, 'Two Bunches\\nN=10'),\n        ('two_bunches', 100, 'Two Bunches\\nN=100'),\n        ('three_clusters', 10, 'Three Clusters\\nN=10'),\n        ('three_clusters', 100, 'Three Clusters\\nN=100')",
        "detail": ".history.notebooks.randomsynapsetest_20241211221914",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221917",
        "description": ".history.notebooks.randomsynapsetest_20241211221917",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.05 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.05 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211221917",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221917",
        "description": ".history.notebooks.randomsynapsetest_20241211221917",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211221917",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221917",
        "description": ".history.notebooks.randomsynapsetest_20241211221917",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211221917",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221917",
        "description": ".history.notebooks.randomsynapsetest_20241211221917",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211221917",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211221917",
        "description": ".history.notebooks.randomsynapsetest_20241211221917",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 10, 'Uniform\\nN=10'),\n        ('uniform', 100, 'Uniform\\nN=100'),\n        ('two_bunches', 10, 'Two Bunches\\nN=10'),\n        ('two_bunches', 100, 'Two Bunches\\nN=100'),\n        ('three_clusters', 10, 'Three Clusters\\nN=10'),\n        ('three_clusters', 100, 'Three Clusters\\nN=100')",
        "detail": ".history.notebooks.randomsynapsetest_20241211221917",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222056",
        "description": ".history.notebooks.randomsynapsetest_20241211222056",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.05 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.05 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211222056",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222056",
        "description": ".history.notebooks.randomsynapsetest_20241211222056",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211222056",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222056",
        "description": ".history.notebooks.randomsynapsetest_20241211222056",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211222056",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222056",
        "description": ".history.notebooks.randomsynapsetest_20241211222056",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211222056",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222056",
        "description": ".history.notebooks.randomsynapsetest_20241211222056",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 100, 'Uniform\\nN=100'),\n        ('uniform', 1000, 'Uniform\\nN=1000'),\n        ('two_bunches', 100, 'Two Bunches\\nN=100'),\n        ('two_bunches', 1000, 'Two Bunches\\nN=1000'),\n        ('three_clusters', 100, 'Three Clusters\\nN=100'),\n        ('three_clusters', 1000, 'Three Clusters\\nN=1000')",
        "detail": ".history.notebooks.randomsynapsetest_20241211222056",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222416",
        "description": ".history.notebooks.randomsynapsetest_20241211222416",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.05 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.05 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211222416",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222416",
        "description": ".history.notebooks.randomsynapsetest_20241211222416",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211222416",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222416",
        "description": ".history.notebooks.randomsynapsetest_20241211222416",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211222416",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222416",
        "description": ".history.notebooks.randomsynapsetest_20241211222416",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211222416",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222416",
        "description": ".history.notebooks.randomsynapsetest_20241211222416",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 100, 'Uniform\\nN=100'),\n        ('uniform', 1000, 'Uniform\\nN=1000'),\n        ('two_bunches', 100, 'Two Bunches\\nN=100'),\n        ('two_bunches', 1000, 'Two Bunches\\nN=1000'),\n        ('three_clusters', 100, 'Three Clusters\\nN=100'),\n        ('three_clusters', 1000, 'Three Clusters\\nN=1000')",
        "detail": ".history.notebooks.randomsynapsetest_20241211222416",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222634",
        "description": ".history.notebooks.randomsynapsetest_20241211222634",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.05 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.05 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211222634",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222634",
        "description": ".history.notebooks.randomsynapsetest_20241211222634",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211222634",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222634",
        "description": ".history.notebooks.randomsynapsetest_20241211222634",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211222634",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222634",
        "description": ".history.notebooks.randomsynapsetest_20241211222634",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211222634",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222634",
        "description": ".history.notebooks.randomsynapsetest_20241211222634",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 100, 'Uniform\\nN=100'),\n        ('two_bunches', 100, 'Two Bunches\\nN=100'),\n        ('three_clusters', 100, 'Three Clusters\\nN=100'),\n        ('uniform', 1000, 'Uniform\\nN=1000'),\n        ('two_bunches', 1000, 'Two Bunches\\nN=1000'),\n        ('three_clusters', 1000, 'Three Clusters\\nN=1000')",
        "detail": ".history.notebooks.randomsynapsetest_20241211222634",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222834",
        "description": ".history.notebooks.randomsynapsetest_20241211222834",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.05 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.05 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211222834",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222834",
        "description": ".history.notebooks.randomsynapsetest_20241211222834",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211222834",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222834",
        "description": ".history.notebooks.randomsynapsetest_20241211222834",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211222834",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222834",
        "description": ".history.notebooks.randomsynapsetest_20241211222834",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211222834",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222834",
        "description": ".history.notebooks.randomsynapsetest_20241211222834",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 100, 'Uniform'),\n        ('two_bunches', 100, 'Two Bunches'),\n        ('three_clusters', 100, 'Three Clusters'),\n        ('uniform', 1000, 'Uniform'),\n        ('two_bunches', 1000, 'Two Bunches'),\n        ('three_clusters', 1000, 'Three Clusters')",
        "detail": ".history.notebooks.randomsynapsetest_20241211222834",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222952",
        "description": ".history.notebooks.randomsynapsetest_20241211222952",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.05 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.05 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211222952",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222952",
        "description": ".history.notebooks.randomsynapsetest_20241211222952",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211222952",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222952",
        "description": ".history.notebooks.randomsynapsetest_20241211222952",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211222952",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222952",
        "description": ".history.notebooks.randomsynapsetest_20241211222952",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211222952",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211222952",
        "description": ".history.notebooks.randomsynapsetest_20241211222952",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 100, 'Uniform'),\n        ('two_bunches', 100, 'Two Bunches'),\n        ('three_clusters', 100, 'Three Clusters'),\n        ('uniform', 1000, 'Uniform'),\n        ('two_bunches', 1000, 'Two Bunches'),\n        ('three_clusters', 1000, 'Three Clusters')",
        "detail": ".history.notebooks.randomsynapsetest_20241211222952",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223429",
        "description": ".history.notebooks.randomsynapsetest_20241211223429",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.05 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.05 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211223429",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223429",
        "description": ".history.notebooks.randomsynapsetest_20241211223429",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211223429",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223429",
        "description": ".history.notebooks.randomsynapsetest_20241211223429",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211223429",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223429",
        "description": ".history.notebooks.randomsynapsetest_20241211223429",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211223429",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223429",
        "description": ".history.notebooks.randomsynapsetest_20241211223429",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 100, 'Uniform'),\n        ('two_bunches', 100, 'Two Bunches'),\n        ('three_clusters', 100, 'Three Clusters'),\n        ('uniform', 1000, 'Uniform'),\n        ('two_bunches', 1000, 'Two Bunches'),\n        ('three_clusters', 1000, 'Three Clusters')",
        "detail": ".history.notebooks.randomsynapsetest_20241211223429",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223554",
        "description": ".history.notebooks.randomsynapsetest_20241211223554",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.05 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.05 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211223554",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223554",
        "description": ".history.notebooks.randomsynapsetest_20241211223554",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211223554",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223554",
        "description": ".history.notebooks.randomsynapsetest_20241211223554",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211223554",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223554",
        "description": ".history.notebooks.randomsynapsetest_20241211223554",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211223554",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223554",
        "description": ".history.notebooks.randomsynapsetest_20241211223554",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 100, 'Uniform'),\n        ('two_bunches', 100, 'Two Bunches'),\n        ('three_clusters', 100, 'Three Clusters'),\n        ('uniform', 1000, 'Uniform'),\n        ('two_bunches', 1000, 'Two Bunches'),\n        ('three_clusters', 1000, 'Three Clusters')",
        "detail": ".history.notebooks.randomsynapsetest_20241211223554",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223635",
        "description": ".history.notebooks.randomsynapsetest_20241211223635",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.05 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.05 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211223635",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223635",
        "description": ".history.notebooks.randomsynapsetest_20241211223635",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211223635",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223635",
        "description": ".history.notebooks.randomsynapsetest_20241211223635",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211223635",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223635",
        "description": ".history.notebooks.randomsynapsetest_20241211223635",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211223635",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223635",
        "description": ".history.notebooks.randomsynapsetest_20241211223635",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 100, 'Uniform'),\n        ('uniform', 1000, 'Uniform'),\n        ('two_bunches', 100, 'Two Bunches'),\n        ('two_bunches', 1000, 'Two Bunches'),\n        ('three_clusters', 100, 'Three Clusters'),\n        ('three_clusters', 1000, 'Three Clusters')",
        "detail": ".history.notebooks.randomsynapsetest_20241211223635",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223742",
        "description": ".history.notebooks.randomsynapsetest_20241211223742",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.05 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.05 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211223742",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223742",
        "description": ".history.notebooks.randomsynapsetest_20241211223742",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211223742",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223742",
        "description": ".history.notebooks.randomsynapsetest_20241211223742",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211223742",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223742",
        "description": ".history.notebooks.randomsynapsetest_20241211223742",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211223742",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223742",
        "description": ".history.notebooks.randomsynapsetest_20241211223742",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 100, 'Uniform'),\n        ('uniform', 1000, 'Uniform'),\n        ('two_bunches', 100, 'Two Bunches'),\n        ('two_bunches', 1000, 'Two Bunches'),\n        ('three_clusters', 100, 'Three Clusters'),\n        ('three_clusters', 1000, 'Three Clusters')",
        "detail": ".history.notebooks.randomsynapsetest_20241211223742",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223817",
        "description": ".history.notebooks.randomsynapsetest_20241211223817",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.05 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.05 * stick_length, n//2 + n%2)\n        ])",
        "detail": ".history.notebooks.randomsynapsetest_20241211223817",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223817",
        "description": ".history.notebooks.randomsynapsetest_20241211223817",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": ".history.notebooks.randomsynapsetest_20241211223817",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223817",
        "description": ".history.notebooks.randomsynapsetest_20241211223817",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": ".history.notebooks.randomsynapsetest_20241211223817",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223817",
        "description": ".history.notebooks.randomsynapsetest_20241211223817",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": ".history.notebooks.randomsynapsetest_20241211223817",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": ".history.notebooks.randomsynapsetest_20241211223817",
        "description": ".history.notebooks.randomsynapsetest_20241211223817",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 100, 'Uniform'),\n        ('uniform', 1000, 'Uniform'),\n        ('two_bunches', 100, 'Two Bunches'),\n        ('two_bunches', 1000, 'Two Bunches'),\n        ('three_clusters', 100, 'Three Clusters'),\n        ('three_clusters', 1000, 'Three Clusters')",
        "detail": ".history.notebooks.randomsynapsetest_20241211223817",
        "documentation": {}
    },
    {
        "label": "load_metrics",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223171609",
        "description": ".history.metrics_analysis_20250223171609",
        "peekOfCode": "def load_metrics():\n    \"\"\"Load pre-calculated metrics from CSV\"\"\"\n    metrics_df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Select only numerical columns for clustering\n    feature_cols = metrics_df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    return metrics_df, feature_cols\ndef perform_clustering_analysis(metrics_df, feature_cols, n_clusters=3):\n    \"\"\"Perform PCA and clustering on the metrics\"\"\"\n    X = metrics_df[feature_cols]",
        "detail": ".history.metrics_analysis_20250223171609",
        "documentation": {}
    },
    {
        "label": "perform_clustering_analysis",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223171609",
        "description": ".history.metrics_analysis_20250223171609",
        "peekOfCode": "def perform_clustering_analysis(metrics_df, feature_cols, n_clusters=3):\n    \"\"\"Perform PCA and clustering on the metrics\"\"\"\n    X = metrics_df[feature_cols]\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    # PCA\n    pca = PCA(n_components=2)\n    X_pca = pca.fit_transform(X_scaled)\n    # K-means clustering\n    kmeans = KMeans(n_clusters=n_clusters, random_state=42)",
        "detail": ".history.metrics_analysis_20250223171609",
        "documentation": {}
    },
    {
        "label": "plot_clusters",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223171609",
        "description": ".history.metrics_analysis_20250223171609",
        "peekOfCode": "def plot_clusters(X_pca, clusters, variance_ratio):\n    \"\"\"Plot the clustering results\"\"\"\n    plt.figure(figsize=(10, 8))\n    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis')\n    plt.xlabel(f'PC1 ({variance_ratio[0]:.2%} variance explained)')\n    plt.ylabel(f'PC2 ({variance_ratio[1]:.2%} variance explained)')\n    plt.title('Synapse Clusters based on Morphological Features')\n    plt.colorbar(scatter, label='Cluster')\n    plt.show()\nif __name__ == \"__main__\":",
        "detail": ".history.metrics_analysis_20250223171609",
        "documentation": {}
    },
    {
        "label": "load_metrics",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223171618",
        "description": ".history.metrics_analysis_20250223171618",
        "peekOfCode": "def load_metrics():\n    \"\"\"Load pre-calculated metrics from CSV\"\"\"\n    metrics_df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Select only numerical columns for clustering\n    feature_cols = metrics_df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    return metrics_df, feature_cols\ndef perform_clustering_analysis(metrics_df, feature_cols, n_clusters=3):\n    \"\"\"Perform PCA and clustering on the metrics\"\"\"\n    X = metrics_df[feature_cols]",
        "detail": ".history.metrics_analysis_20250223171618",
        "documentation": {}
    },
    {
        "label": "perform_clustering_analysis",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223171618",
        "description": ".history.metrics_analysis_20250223171618",
        "peekOfCode": "def perform_clustering_analysis(metrics_df, feature_cols, n_clusters=3):\n    \"\"\"Perform PCA and clustering on the metrics\"\"\"\n    X = metrics_df[feature_cols]\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    # PCA\n    pca = PCA(n_components=2)\n    X_pca = pca.fit_transform(X_scaled)\n    # K-means clustering\n    kmeans = KMeans(n_clusters=n_clusters, random_state=42)",
        "detail": ".history.metrics_analysis_20250223171618",
        "documentation": {}
    },
    {
        "label": "plot_clusters",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223171618",
        "description": ".history.metrics_analysis_20250223171618",
        "peekOfCode": "def plot_clusters(X_pca, clusters, variance_ratio):\n    \"\"\"Plot the clustering results\"\"\"\n    plt.figure(figsize=(10, 8))\n    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis')\n    plt.xlabel(f'PC1 ({variance_ratio[0]:.2%} variance explained)')\n    plt.ylabel(f'PC2 ({variance_ratio[1]:.2%} variance explained)')\n    plt.title('Synapse Clusters based on Morphological Features')\n    plt.colorbar(scatter, label='Cluster')\n    plt.show()\nif __name__ == \"__main__\":",
        "detail": ".history.metrics_analysis_20250223171618",
        "documentation": {}
    },
    {
        "label": "load_metrics",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172003",
        "description": ".history.metrics_analysis_20250223172003",
        "peekOfCode": "def load_metrics():\n    \"\"\"Load pre-calculated metrics from CSV\"\"\"\n    metrics_df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Select only numerical columns for clustering\n    feature_cols = metrics_df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    return metrics_df, feature_cols\ndef perform_clustering_analysis(metrics_df, feature_cols, n_clusters=3, method='pca'):\n    \"\"\"Perform dimensionality reduction and clustering on the metrics\"\"\"\n    X = metrics_df[feature_cols]",
        "detail": ".history.metrics_analysis_20250223172003",
        "documentation": {}
    },
    {
        "label": "perform_clustering_analysis",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172003",
        "description": ".history.metrics_analysis_20250223172003",
        "peekOfCode": "def perform_clustering_analysis(metrics_df, feature_cols, n_clusters=3, method='pca'):\n    \"\"\"Perform dimensionality reduction and clustering on the metrics\"\"\"\n    X = metrics_df[feature_cols]\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    # Dimensionality reduction\n    if method == 'pca':\n        reducer = PCA(n_components=2)\n        X_reduced = reducer.fit_transform(X_scaled)\n        explained_var = reducer.explained_variance_ratio_",
        "detail": ".history.metrics_analysis_20250223172003",
        "documentation": {}
    },
    {
        "label": "plot_clusters",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172003",
        "description": ".history.metrics_analysis_20250223172003",
        "peekOfCode": "def plot_clusters(X_reduced, clusters, variance_ratio=None, method='pca'):\n    \"\"\"Plot the clustering results\"\"\"\n    plt.figure(figsize=(10, 8))\n    scatter = plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=clusters, cmap='viridis')\n    if method == 'pca':\n        plt.xlabel(f'PC1 ({variance_ratio[0]:.2%} variance explained)')\n        plt.ylabel(f'PC2 ({variance_ratio[1]:.2%} variance explained)')\n        title = 'Synapse Clusters (PCA)'\n    else:\n        plt.xlabel('UMAP1')",
        "detail": ".history.metrics_analysis_20250223172003",
        "documentation": {}
    },
    {
        "label": "load_metrics",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172004",
        "description": ".history.metrics_analysis_20250223172004",
        "peekOfCode": "def load_metrics():\n    \"\"\"Load pre-calculated metrics from CSV\"\"\"\n    metrics_df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Select only numerical columns for clustering\n    feature_cols = metrics_df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    return metrics_df, feature_cols\ndef perform_clustering_analysis(metrics_df, feature_cols, n_clusters=3, method='pca'):\n    \"\"\"Perform dimensionality reduction and clustering on the metrics\"\"\"\n    X = metrics_df[feature_cols]",
        "detail": ".history.metrics_analysis_20250223172004",
        "documentation": {}
    },
    {
        "label": "perform_clustering_analysis",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172004",
        "description": ".history.metrics_analysis_20250223172004",
        "peekOfCode": "def perform_clustering_analysis(metrics_df, feature_cols, n_clusters=3, method='pca'):\n    \"\"\"Perform dimensionality reduction and clustering on the metrics\"\"\"\n    X = metrics_df[feature_cols]\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    # Dimensionality reduction\n    if method == 'pca':\n        reducer = PCA(n_components=2)\n        X_reduced = reducer.fit_transform(X_scaled)\n        explained_var = reducer.explained_variance_ratio_",
        "detail": ".history.metrics_analysis_20250223172004",
        "documentation": {}
    },
    {
        "label": "plot_clusters",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172004",
        "description": ".history.metrics_analysis_20250223172004",
        "peekOfCode": "def plot_clusters(X_reduced, clusters, variance_ratio=None, method='pca'):\n    \"\"\"Plot the clustering results\"\"\"\n    plt.figure(figsize=(10, 8))\n    scatter = plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=clusters, cmap='viridis')\n    if method == 'pca':\n        plt.xlabel(f'PC1 ({variance_ratio[0]:.2%} variance explained)')\n        plt.ylabel(f'PC2 ({variance_ratio[1]:.2%} variance explained)')\n        title = 'Synapse Clusters (PCA)'\n    else:\n        plt.xlabel('UMAP1')",
        "detail": ".history.metrics_analysis_20250223172004",
        "documentation": {}
    },
    {
        "label": "load_metrics",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172514",
        "description": ".history.metrics_analysis_20250223172514",
        "peekOfCode": "def load_metrics():\n    \"\"\"Load pre-calculated metrics from CSV\"\"\"\n    metrics_df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Select only numerical columns for clustering\n    feature_cols = metrics_df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    return metrics_df, feature_cols\ndef perform_clustering_analysis(metrics_df, feature_cols, n_clusters=3, method='pca'):\n    \"\"\"Perform dimensionality reduction and clustering on the metrics\"\"\"\n    X = metrics_df[feature_cols]",
        "detail": ".history.metrics_analysis_20250223172514",
        "documentation": {}
    },
    {
        "label": "perform_clustering_analysis",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172514",
        "description": ".history.metrics_analysis_20250223172514",
        "peekOfCode": "def perform_clustering_analysis(metrics_df, feature_cols, n_clusters=3, method='pca'):\n    \"\"\"Perform dimensionality reduction and clustering on the metrics\"\"\"\n    X = metrics_df[feature_cols]\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    # Dimensionality reduction\n    if method == 'pca':\n        reducer = PCA(n_components=2)\n        X_reduced = reducer.fit_transform(X_scaled)\n        explained_var = reducer.explained_variance_ratio_",
        "detail": ".history.metrics_analysis_20250223172514",
        "documentation": {}
    },
    {
        "label": "plot_clusters",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172514",
        "description": ".history.metrics_analysis_20250223172514",
        "peekOfCode": "def plot_clusters(X_reduced, clusters, variance_ratio=None, method='pca'):\n    \"\"\"Plot the clustering results\"\"\"\n    plt.figure(figsize=(10, 8))\n    scatter = plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=clusters, cmap='viridis')\n    if method == 'pca':\n        plt.xlabel(f'PC1 ({variance_ratio[0]:.2%} variance explained)')\n        plt.ylabel(f'PC2 ({variance_ratio[1]:.2%} variance explained)')\n        title = 'Synapse Clusters (PCA)'\n    else:\n        plt.xlabel('UMAP1')",
        "detail": ".history.metrics_analysis_20250223172514",
        "documentation": {}
    },
    {
        "label": "perform_umap",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172514",
        "description": ".history.metrics_analysis_20250223172514",
        "peekOfCode": "def perform_umap(metrics_df, feature_cols):\n    \"\"\"Perform UMAP dimensionality reduction\"\"\"\n    X = metrics_df[feature_cols]\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    reducer = umap.UMAP(random_state=42)\n    X_reduced = reducer.fit_transform(X_scaled)\n    return X_reduced\ndef plot_cell_types(metrics_df, X_umap):\n    \"\"\"Plot UMAP colored by different cell type classifications\"\"\"",
        "detail": ".history.metrics_analysis_20250223172514",
        "documentation": {}
    },
    {
        "label": "plot_cell_types",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172514",
        "description": ".history.metrics_analysis_20250223172514",
        "peekOfCode": "def plot_cell_types(metrics_df, X_umap):\n    \"\"\"Plot UMAP colored by different cell type classifications\"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n    # Define the subplots data\n    plots = [\n        ('pre_syn_cell_type', 'Pre-synaptic Cell Type', 0, 0),\n        ('pre_syn_clf_type', 'Pre-synaptic Classification', 0, 1),\n        ('post_syn_cell_type', 'Post-synaptic Cell Type', 1, 0),\n        ('post_syn_clf_type', 'Post-synaptic Classification', 1, 1)\n    ]",
        "detail": ".history.metrics_analysis_20250223172514",
        "documentation": {}
    },
    {
        "label": "load_metrics",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172619",
        "description": ".history.metrics_analysis_20250223172619",
        "peekOfCode": "def load_metrics():\n    \"\"\"Load pre-calculated metrics from CSV\"\"\"\n    metrics_df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Select only numerical columns for clustering\n    feature_cols = metrics_df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    return metrics_df, feature_cols\ndef perform_clustering_analysis(metrics_df, feature_cols, n_clusters=3, method='pca'):\n    \"\"\"Perform dimensionality reduction and clustering on the metrics\"\"\"\n    X = metrics_df[feature_cols]",
        "detail": ".history.metrics_analysis_20250223172619",
        "documentation": {}
    },
    {
        "label": "perform_clustering_analysis",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172619",
        "description": ".history.metrics_analysis_20250223172619",
        "peekOfCode": "def perform_clustering_analysis(metrics_df, feature_cols, n_clusters=3, method='pca'):\n    \"\"\"Perform dimensionality reduction and clustering on the metrics\"\"\"\n    X = metrics_df[feature_cols]\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    # Dimensionality reduction\n    if method == 'pca':\n        reducer = PCA(n_components=2)\n        X_reduced = reducer.fit_transform(X_scaled)\n        explained_var = reducer.explained_variance_ratio_",
        "detail": ".history.metrics_analysis_20250223172619",
        "documentation": {}
    },
    {
        "label": "plot_clusters",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172619",
        "description": ".history.metrics_analysis_20250223172619",
        "peekOfCode": "def plot_clusters(X_reduced, clusters, variance_ratio=None, method='pca'):\n    \"\"\"Plot the clustering results\"\"\"\n    plt.figure(figsize=(10, 8))\n    scatter = plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=clusters, cmap='viridis')\n    if method == 'pca':\n        plt.xlabel(f'PC1 ({variance_ratio[0]:.2%} variance explained)')\n        plt.ylabel(f'PC2 ({variance_ratio[1]:.2%} variance explained)')\n        title = 'Synapse Clusters (PCA)'\n    else:\n        plt.xlabel('UMAP1')",
        "detail": ".history.metrics_analysis_20250223172619",
        "documentation": {}
    },
    {
        "label": "perform_umap",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172619",
        "description": ".history.metrics_analysis_20250223172619",
        "peekOfCode": "def perform_umap(metrics_df, feature_cols):\n    \"\"\"Perform UMAP dimensionality reduction\"\"\"\n    X = metrics_df[feature_cols]\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    reducer = umap.UMAP(random_state=42)\n    X_reduced = reducer.fit_transform(X_scaled)\n    return X_reduced\ndef plot_cell_types(metrics_df, X_umap):\n    \"\"\"Plot UMAP colored by different cell type classifications\"\"\"",
        "detail": ".history.metrics_analysis_20250223172619",
        "documentation": {}
    },
    {
        "label": "plot_cell_types",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172619",
        "description": ".history.metrics_analysis_20250223172619",
        "peekOfCode": "def plot_cell_types(metrics_df, X_umap):\n    \"\"\"Plot UMAP colored by different cell type classifications\"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n    # Define the subplots data\n    plots = [\n        ('pre_syn_cell_type', 'Pre-synaptic Cell Type', 0, 0),\n        ('pre_syn_clf_type', 'Pre-synaptic Classification', 0, 1),\n        ('post_syn_cell_type', 'Post-synaptic Cell Type', 1, 0),\n        ('post_syn_clf_type', 'Post-synaptic Classification', 1, 1)\n    ]",
        "detail": ".history.metrics_analysis_20250223172619",
        "documentation": {}
    },
    {
        "label": "load_metrics",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172621",
        "description": ".history.metrics_analysis_20250223172621",
        "peekOfCode": "def load_metrics():\n    \"\"\"Load pre-calculated metrics from CSV\"\"\"\n    metrics_df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Select only numerical columns for clustering\n    feature_cols = metrics_df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    return metrics_df, feature_cols\ndef perform_clustering_analysis(metrics_df, feature_cols, n_clusters=3, method='pca'):\n    \"\"\"Perform dimensionality reduction and clustering on the metrics\"\"\"\n    X = metrics_df[feature_cols]",
        "detail": ".history.metrics_analysis_20250223172621",
        "documentation": {}
    },
    {
        "label": "perform_clustering_analysis",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172621",
        "description": ".history.metrics_analysis_20250223172621",
        "peekOfCode": "def perform_clustering_analysis(metrics_df, feature_cols, n_clusters=3, method='pca'):\n    \"\"\"Perform dimensionality reduction and clustering on the metrics\"\"\"\n    X = metrics_df[feature_cols]\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    # Dimensionality reduction\n    if method == 'pca':\n        reducer = PCA(n_components=2)\n        X_reduced = reducer.fit_transform(X_scaled)\n        explained_var = reducer.explained_variance_ratio_",
        "detail": ".history.metrics_analysis_20250223172621",
        "documentation": {}
    },
    {
        "label": "plot_clusters",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172621",
        "description": ".history.metrics_analysis_20250223172621",
        "peekOfCode": "def plot_clusters(X_reduced, clusters, variance_ratio=None, method='pca'):\n    \"\"\"Plot the clustering results\"\"\"\n    plt.figure(figsize=(10, 8))\n    scatter = plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=clusters, cmap='viridis')\n    if method == 'pca':\n        plt.xlabel(f'PC1 ({variance_ratio[0]:.2%} variance explained)')\n        plt.ylabel(f'PC2 ({variance_ratio[1]:.2%} variance explained)')\n        title = 'Synapse Clusters (PCA)'\n    else:\n        plt.xlabel('UMAP1')",
        "detail": ".history.metrics_analysis_20250223172621",
        "documentation": {}
    },
    {
        "label": "perform_umap",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172621",
        "description": ".history.metrics_analysis_20250223172621",
        "peekOfCode": "def perform_umap(metrics_df, feature_cols):\n    \"\"\"Perform UMAP dimensionality reduction\"\"\"\n    X = metrics_df[feature_cols]\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    reducer = umap.UMAP(random_state=42)\n    X_reduced = reducer.fit_transform(X_scaled)\n    return X_reduced\ndef plot_cell_types(metrics_df, X_umap):\n    \"\"\"Plot UMAP colored by different cell type classifications\"\"\"",
        "detail": ".history.metrics_analysis_20250223172621",
        "documentation": {}
    },
    {
        "label": "plot_cell_types",
        "kind": 2,
        "importPath": ".history.metrics_analysis_20250223172621",
        "description": ".history.metrics_analysis_20250223172621",
        "peekOfCode": "def plot_cell_types(metrics_df, X_umap):\n    \"\"\"Plot UMAP colored by different cell type classifications\"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n    # Define the subplots data\n    plots = [\n        ('pre_syn_cell_type', 'Pre-synaptic Cell Type', 0, 0),\n        ('pre_syn_clf_type', 'Pre-synaptic Classification', 0, 1),\n        ('post_syn_cell_type', 'Post-synaptic Cell Type', 1, 0),\n        ('post_syn_clf_type', 'Post-synaptic Classification', 1, 1)\n    ]",
        "detail": ".history.metrics_analysis_20250223172621",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "kind": 2,
        "importPath": ".history.synapse_analysis_20250223153819",
        "description": ".history.synapse_analysis_20250223153819",
        "peekOfCode": "def synapse_size(pre_mask, post_mask):\n    \"\"\"Calculate synapse size metrics.\"\"\"\n    synapse_mask = pre_mask | post_mask\n    synapse_area = np.sum(synapse_mask)\n    pre_area = np.sum(pre_mask)\n    post_area = np.sum(post_mask)\n    pre_post_ratio = pre_area / post_area\n    return synapse_area, pre_area, post_area, pre_post_ratio\ndef synapse_shape(pre_mask, post_mask):\n    \"\"\"Calculate synapse shape metrics.\"\"\"",
        "detail": ".history.synapse_analysis_20250223153819",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "kind": 2,
        "importPath": ".history.synapse_analysis_20250223153819",
        "description": ".history.synapse_analysis_20250223153819",
        "peekOfCode": "def synapse_shape(pre_mask, post_mask):\n    \"\"\"Calculate synapse shape metrics.\"\"\"\n    synapse_mask = pre_mask | post_mask\n    perimeter = measure.perimeter(synapse_mask)\n    circularity = 4 * np.pi * np.sum(synapse_mask) / (perimeter ** 2)\n    return perimeter, circularity\ndef synapse_intensity(image, pre_mask, post_mask):\n    \"\"\"Calculate synapse intensity metrics.\"\"\"\n    synapse_mask = pre_mask | post_mask\n    synapse_intensities = image[synapse_mask]",
        "detail": ".history.synapse_analysis_20250223153819",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "kind": 2,
        "importPath": ".history.synapse_analysis_20250223153819",
        "description": ".history.synapse_analysis_20250223153819",
        "peekOfCode": "def synapse_intensity(image, pre_mask, post_mask):\n    \"\"\"Calculate synapse intensity metrics.\"\"\"\n    synapse_mask = pre_mask | post_mask\n    synapse_intensities = image[synapse_mask]\n    mean_intensity = np.mean(synapse_intensities)\n    median_intensity = np.median(synapse_intensities)\n    std_intensity = np.std(synapse_intensities)\n    return mean_intensity, median_intensity, std_intensity\ndef synapse_distance(pre_mask, post_mask):\n    \"\"\"Calculate distance between pre- and post-synaptic regions.\"\"\"",
        "detail": ".history.synapse_analysis_20250223153819",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "kind": 2,
        "importPath": ".history.synapse_analysis_20250223153819",
        "description": ".history.synapse_analysis_20250223153819",
        "peekOfCode": "def synapse_distance(pre_mask, post_mask):\n    \"\"\"Calculate distance between pre- and post-synaptic regions.\"\"\"\n    pre_centroid = measure.centroid(pre_mask)\n    post_centroid = measure.centroid(post_mask)\n    distance = np.sqrt((pre_centroid[0] - post_centroid[0]) ** 2 +\n                       (pre_centroid[1] - post_centroid[1]) ** 2)\n    return distance\ndef synapse_colocalization(pre_mask, post_mask):\n    \"\"\"Calculate synapse co-localization metrics.\"\"\"\n    intersection = pre_mask & post_mask",
        "detail": ".history.synapse_analysis_20250223153819",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "kind": 2,
        "importPath": ".history.synapse_analysis_20250223153819",
        "description": ".history.synapse_analysis_20250223153819",
        "peekOfCode": "def synapse_colocalization(pre_mask, post_mask):\n    \"\"\"Calculate synapse co-localization metrics.\"\"\"\n    intersection = pre_mask & post_mask\n    union = pre_mask | post_mask\n    jaccard_index = np.sum(intersection) / np.sum(union)\n    pre_overlap = np.sum(intersection) / np.sum(pre_mask)\n    post_overlap = np.sum(intersection) / np.sum(post_mask)\n    return jaccard_index, pre_overlap, post_overlap\ndef synapse_morphology(pre_mask, post_mask):\n    \"\"\"Calculate synapse morphology metrics.\"\"\"",
        "detail": ".history.synapse_analysis_20250223153819",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "kind": 2,
        "importPath": ".history.synapse_analysis_20250223153819",
        "description": ".history.synapse_analysis_20250223153819",
        "peekOfCode": "def synapse_morphology(pre_mask, post_mask):\n    \"\"\"Calculate synapse morphology metrics.\"\"\"\n    synapse_mask = pre_mask | post_mask\n    labeled_synapse = measure.label(synapse_mask)\n    properties = measure.regionprops(labeled_synapse)\n    if properties:\n        major_axis_length = properties[0].major_axis_length\n        minor_axis_length = properties[0].minor_axis_length\n    else:\n        major_axis_length = 0",
        "detail": ".history.synapse_analysis_20250223153819",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "kind": 2,
        "importPath": ".history.synapse_analysis_20250223153821",
        "description": ".history.synapse_analysis_20250223153821",
        "peekOfCode": "def synapse_size(pre_mask, post_mask):\n    \"\"\"Calculate synapse size metrics.\"\"\"\n    synapse_mask = pre_mask | post_mask\n    synapse_area = np.sum(synapse_mask)\n    pre_area = np.sum(pre_mask)\n    post_area = np.sum(post_mask)\n    pre_post_ratio = pre_area / post_area\n    return synapse_area, pre_area, post_area, pre_post_ratio\ndef synapse_shape(pre_mask, post_mask):\n    \"\"\"Calculate synapse shape metrics.\"\"\"",
        "detail": ".history.synapse_analysis_20250223153821",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "kind": 2,
        "importPath": ".history.synapse_analysis_20250223153821",
        "description": ".history.synapse_analysis_20250223153821",
        "peekOfCode": "def synapse_shape(pre_mask, post_mask):\n    \"\"\"Calculate synapse shape metrics.\"\"\"\n    synapse_mask = pre_mask | post_mask\n    perimeter = measure.perimeter(synapse_mask)\n    circularity = 4 * np.pi * np.sum(synapse_mask) / (perimeter ** 2)\n    return perimeter, circularity\ndef synapse_intensity(image, pre_mask, post_mask):\n    \"\"\"Calculate synapse intensity metrics.\"\"\"\n    synapse_mask = pre_mask | post_mask\n    synapse_intensities = image[synapse_mask]",
        "detail": ".history.synapse_analysis_20250223153821",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "kind": 2,
        "importPath": ".history.synapse_analysis_20250223153821",
        "description": ".history.synapse_analysis_20250223153821",
        "peekOfCode": "def synapse_intensity(image, pre_mask, post_mask):\n    \"\"\"Calculate synapse intensity metrics.\"\"\"\n    synapse_mask = pre_mask | post_mask\n    synapse_intensities = image[synapse_mask]\n    mean_intensity = np.mean(synapse_intensities)\n    median_intensity = np.median(synapse_intensities)\n    std_intensity = np.std(synapse_intensities)\n    return mean_intensity, median_intensity, std_intensity\ndef synapse_distance(pre_mask, post_mask):\n    \"\"\"Calculate distance between pre- and post-synaptic regions.\"\"\"",
        "detail": ".history.synapse_analysis_20250223153821",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "kind": 2,
        "importPath": ".history.synapse_analysis_20250223153821",
        "description": ".history.synapse_analysis_20250223153821",
        "peekOfCode": "def synapse_distance(pre_mask, post_mask):\n    \"\"\"Calculate distance between pre- and post-synaptic regions.\"\"\"\n    pre_centroid = measure.centroid(pre_mask)\n    post_centroid = measure.centroid(post_mask)\n    distance = np.sqrt((pre_centroid[0] - post_centroid[0]) ** 2 +\n                       (pre_centroid[1] - post_centroid[1]) ** 2)\n    return distance\ndef synapse_colocalization(pre_mask, post_mask):\n    \"\"\"Calculate synapse co-localization metrics.\"\"\"\n    intersection = pre_mask & post_mask",
        "detail": ".history.synapse_analysis_20250223153821",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "kind": 2,
        "importPath": ".history.synapse_analysis_20250223153821",
        "description": ".history.synapse_analysis_20250223153821",
        "peekOfCode": "def synapse_colocalization(pre_mask, post_mask):\n    \"\"\"Calculate synapse co-localization metrics.\"\"\"\n    intersection = pre_mask & post_mask\n    union = pre_mask | post_mask\n    jaccard_index = np.sum(intersection) / np.sum(union)\n    pre_overlap = np.sum(intersection) / np.sum(pre_mask)\n    post_overlap = np.sum(intersection) / np.sum(post_mask)\n    return jaccard_index, pre_overlap, post_overlap\ndef synapse_morphology(pre_mask, post_mask):\n    \"\"\"Calculate synapse morphology metrics.\"\"\"",
        "detail": ".history.synapse_analysis_20250223153821",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "kind": 2,
        "importPath": ".history.synapse_analysis_20250223153821",
        "description": ".history.synapse_analysis_20250223153821",
        "peekOfCode": "def synapse_morphology(pre_mask, post_mask):\n    \"\"\"Calculate synapse morphology metrics.\"\"\"\n    synapse_mask = pre_mask | post_mask\n    labeled_synapse = measure.label(synapse_mask)\n    properties = measure.regionprops(labeled_synapse)\n    if properties:\n        major_axis_length = properties[0].major_axis_length\n        minor_axis_length = properties[0].minor_axis_length\n    else:\n        major_axis_length = 0",
        "detail": ".history.synapse_analysis_20250223153821",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223185739",
        "description": ".history.synapse_classification_20250223185739",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Create E/I labels from cell types\n    df['is_excitatory'] = df['pre_syn_clf_type'].str.contains('E', case=False)\n    # Select numerical features for classification\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id', 'is_excitatory'])\n    X = df[feature_cols]\n    y = df['is_excitatory']",
        "detail": ".history.synapse_classification_20250223185739",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223185739",
        "description": ".history.synapse_classification_20250223185739",
        "peekOfCode": "def evaluate_classifiers(X, y, n_splits=5):\n    \"\"\"Evaluate multiple classifiers using k-fold cross validation\"\"\"\n    # Initialize classifiers\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42),\n        'SVM': SVC(random_state=42),\n        'Neural Net': MLPClassifier(random_state=42, max_iter=1000)\n    }\n    # Scale features\n    scaler = StandardScaler()",
        "detail": ".history.synapse_classification_20250223185739",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223185739",
        "description": ".history.synapse_classification_20250223185739",
        "peekOfCode": "def plot_results(results):\n    \"\"\"Plot cross validation results\"\"\"\n    plt.figure(figsize=(10, 6))\n    plt.boxplot(results.values(), labels=results.keys())\n    plt.title('Classifier Performance Comparison')\n    plt.ylabel('Accuracy')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\nif __name__ == \"__main__\":",
        "detail": ".history.synapse_classification_20250223185739",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223185740",
        "description": ".history.synapse_classification_20250223185740",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Create E/I labels from cell types\n    df['is_excitatory'] = df['pre_syn_clf_type'].str.contains('E', case=False)\n    # Select numerical features for classification\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id', 'is_excitatory'])\n    X = df[feature_cols]\n    y = df['is_excitatory']",
        "detail": ".history.synapse_classification_20250223185740",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223185740",
        "description": ".history.synapse_classification_20250223185740",
        "peekOfCode": "def evaluate_classifiers(X, y, n_splits=5):\n    \"\"\"Evaluate multiple classifiers using k-fold cross validation\"\"\"\n    # Initialize classifiers\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42),\n        'SVM': SVC(random_state=42),\n        'Neural Net': MLPClassifier(random_state=42, max_iter=1000)\n    }\n    # Scale features\n    scaler = StandardScaler()",
        "detail": ".history.synapse_classification_20250223185740",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223185740",
        "description": ".history.synapse_classification_20250223185740",
        "peekOfCode": "def plot_results(results):\n    \"\"\"Plot cross validation results\"\"\"\n    plt.figure(figsize=(10, 6))\n    plt.boxplot(results.values(), labels=results.keys())\n    plt.title('Classifier Performance Comparison')\n    plt.ylabel('Accuracy')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\nif __name__ == \"__main__\":",
        "detail": ".history.synapse_classification_20250223185740",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223185831",
        "description": ".history.synapse_classification_20250223185831",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Select numerical features for classification first\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types\n    df['is_excitatory'] = df['pre_syn_clf_type'].str.contains('E', case=False)\n    X = df[feature_cols]\n    y = df['is_excitatory']",
        "detail": ".history.synapse_classification_20250223185831",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223185831",
        "description": ".history.synapse_classification_20250223185831",
        "peekOfCode": "def evaluate_classifiers(X, y, n_splits=5):\n    \"\"\"Evaluate multiple classifiers using k-fold cross validation\"\"\"\n    # Initialize classifiers\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42),\n        'SVM': SVC(random_state=42),\n        'Neural Net': MLPClassifier(random_state=42, max_iter=1000)\n    }\n    # Scale features\n    scaler = StandardScaler()",
        "detail": ".history.synapse_classification_20250223185831",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223185831",
        "description": ".history.synapse_classification_20250223185831",
        "peekOfCode": "def plot_results(results):\n    \"\"\"Plot cross validation results\"\"\"\n    plt.figure(figsize=(10, 6))\n    plt.boxplot(results.values(), labels=results.keys())\n    plt.title('Classifier Performance Comparison')\n    plt.ylabel('Accuracy')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\nif __name__ == \"__main__\":",
        "detail": ".history.synapse_classification_20250223185831",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190017",
        "description": ".history.synapse_classification_20250223190017",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Select numerical features for classification first\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types\n    df['is_excitatory'] = df['pre_syn_clf_type'].str.contains('E', case=False)\n    X = df[feature_cols]\n    y = df['is_excitatory']",
        "detail": ".history.synapse_classification_20250223190017",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190017",
        "description": ".history.synapse_classification_20250223190017",
        "peekOfCode": "def evaluate_classifiers(X, y, n_splits=5):\n    \"\"\"Evaluate multiple classifiers using k-fold cross validation\"\"\"\n    # Initialize classifiers\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42),\n        'SVM': SVC(random_state=42),\n        'Neural Net': MLPClassifier(random_state=42, max_iter=1000)\n    }\n    # Scale features\n    scaler = StandardScaler()",
        "detail": ".history.synapse_classification_20250223190017",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190017",
        "description": ".history.synapse_classification_20250223190017",
        "peekOfCode": "def plot_results(results, confusion_matrices):\n    \"\"\"Plot cross validation results and confusion matrices\"\"\"\n    n_classifiers = len(results)\n    fig, axes = plt.subplots(2, n_classifiers, figsize=(15, 10))\n    # Plot accuracy boxplots\n    axes[0, 1].boxplot(results.values(), labels=results.keys())\n    axes[0, 1].set_title('Classifier Performance Comparison')\n    axes[0, 1].set_ylabel('Accuracy')\n    axes[0, 1].set_xticklabels(results.keys(), rotation=45)\n    # Hide other plots in top row",
        "detail": ".history.synapse_classification_20250223190017",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190020",
        "description": ".history.synapse_classification_20250223190020",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Select numerical features for classification first\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types\n    df['is_excitatory'] = df['pre_syn_clf_type'].str.contains('E', case=False)\n    X = df[feature_cols]\n    y = df['is_excitatory']",
        "detail": ".history.synapse_classification_20250223190020",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190020",
        "description": ".history.synapse_classification_20250223190020",
        "peekOfCode": "def evaluate_classifiers(X, y, n_splits=5):\n    \"\"\"Evaluate multiple classifiers using k-fold cross validation\"\"\"\n    # Initialize classifiers\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42),\n        'SVM': SVC(random_state=42),\n        'Neural Net': MLPClassifier(random_state=42, max_iter=1000)\n    }\n    # Scale features\n    scaler = StandardScaler()",
        "detail": ".history.synapse_classification_20250223190020",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190020",
        "description": ".history.synapse_classification_20250223190020",
        "peekOfCode": "def plot_results(results, confusion_matrices):\n    \"\"\"Plot cross validation results and confusion matrices\"\"\"\n    n_classifiers = len(results)\n    fig, axes = plt.subplots(2, n_classifiers, figsize=(15, 10))\n    # Plot accuracy boxplots\n    axes[0, 1].boxplot(results.values(), labels=results.keys())\n    axes[0, 1].set_title('Classifier Performance Comparison')\n    axes[0, 1].set_ylabel('Accuracy')\n    axes[0, 1].set_xticklabels(results.keys(), rotation=45)\n    # Hide other plots in top row",
        "detail": ".history.synapse_classification_20250223190020",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190139",
        "description": ".history.synapse_classification_20250223190139",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Select numerical features for classification first\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types\n    df['is_excitatory'] = df['pre_syn_clf_type'].str.contains('E', case=False)\n    X = df[feature_cols]\n    y = df['is_excitatory']",
        "detail": ".history.synapse_classification_20250223190139",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190139",
        "description": ".history.synapse_classification_20250223190139",
        "peekOfCode": "def evaluate_classifiers(X, y, n_splits=5):\n    \"\"\"Evaluate multiple classifiers using k-fold cross validation\"\"\"\n    # Initialize classifiers\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42),\n        'SVM': SVC(random_state=42),\n        'Neural Net': MLPClassifier(random_state=42, max_iter=1000)\n    }\n    # Scale features\n    scaler = StandardScaler()",
        "detail": ".history.synapse_classification_20250223190139",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190139",
        "description": ".history.synapse_classification_20250223190139",
        "peekOfCode": "def plot_results(results, confusion_matrices):\n    \"\"\"Plot cross validation results and confusion matrices\"\"\"\n    n_classifiers = len(results)\n    fig, axes = plt.subplots(2, n_classifiers, figsize=(15, 10))\n    # Plot accuracy boxplots\n    axes[0, 1].boxplot(results.values(), labels=results.keys())\n    axes[0, 1].set_title('Classifier Performance Comparison')\n    axes[0, 1].set_ylabel('Accuracy')\n    axes[0, 1].set_xticklabels(results.keys(), rotation=45)\n    # Hide other plots in top row",
        "detail": ".history.synapse_classification_20250223190139",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190712",
        "description": ".history.synapse_classification_20250223190712",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Select numerical features for classification first\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types\n    df['is_excitatory'] = df['pre_syn_clf_type'].str.contains('E', case=False)\n    X = df[feature_cols]\n    y = df['is_excitatory']",
        "detail": ".history.synapse_classification_20250223190712",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190712",
        "description": ".history.synapse_classification_20250223190712",
        "peekOfCode": "def evaluate_classifiers(X, y, n_splits=5):\n    \"\"\"Evaluate multiple classifiers using k-fold cross validation\"\"\"\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42, class_weight='balanced'),\n        'SVM': SVC(random_state=42, class_weight='balanced'),\n        'Neural Net': MLPClassifier(random_state=42, max_iter=1000)\n    }\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)",
        "detail": ".history.synapse_classification_20250223190712",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190712",
        "description": ".history.synapse_classification_20250223190712",
        "peekOfCode": "def plot_results(results, confusion_matrices):\n    \"\"\"Plot cross validation results and confusion matrices\"\"\"\n    n_classifiers = len(results)\n    fig, axes = plt.subplots(2, n_classifiers, figsize=(15, 10))\n    # Plot accuracy boxplots\n    axes[0, 1].boxplot(results.values(), labels=results.keys())\n    axes[0, 1].set_title('Classifier Performance Comparison')\n    axes[0, 1].set_ylabel('Accuracy')\n    axes[0, 1].set_xticklabels(results.keys(), rotation=45)\n    # Hide other plots in top row",
        "detail": ".history.synapse_classification_20250223190712",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190806",
        "description": ".history.synapse_classification_20250223190806",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Select numerical features for classification first\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types\n    df['is_excitatory'] = df['pre_syn_clf_type'].str.contains('E', case=False)\n    X = df[feature_cols]\n    y = df['is_excitatory']",
        "detail": ".history.synapse_classification_20250223190806",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190806",
        "description": ".history.synapse_classification_20250223190806",
        "peekOfCode": "def evaluate_classifiers(X, y, n_splits=5):\n    \"\"\"Evaluate multiple classifiers using k-fold cross validation\"\"\"\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42, class_weight='balanced'),\n        'SVM': SVC(random_state=42, class_weight='balanced'),\n        'Neural Net': MLPClassifier(random_state=42, max_iter=1000)\n    }\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)",
        "detail": ".history.synapse_classification_20250223190806",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190806",
        "description": ".history.synapse_classification_20250223190806",
        "peekOfCode": "def plot_results(results, confusion_matrices):\n    \"\"\"Plot cross validation results and confusion matrices\"\"\"\n    n_classifiers = len(results)\n    fig, axes = plt.subplots(2, n_classifiers, figsize=(15, 10))\n    # Plot accuracy boxplots\n    axes[0, 1].boxplot(results.values(), labels=results.keys())\n    axes[0, 1].set_title('Classifier Performance Comparison')\n    axes[0, 1].set_ylabel('Accuracy')\n    axes[0, 1].set_xticklabels(results.keys(), rotation=45)\n    # Hide other plots in top row",
        "detail": ".history.synapse_classification_20250223190806",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190906",
        "description": ".history.synapse_classification_20250223190906",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Print class distribution to understand imbalance\n    print(\"\\nClass distribution:\")\n    print(df['pre_syn_clf_type'].value_counts())\n    # Select numerical features for classification\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types",
        "detail": ".history.synapse_classification_20250223190906",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190906",
        "description": ".history.synapse_classification_20250223190906",
        "peekOfCode": "def evaluate_classifiers(X, y, n_splits=5):\n    \"\"\"Evaluate multiple classifiers using k-fold cross validation\"\"\"\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42, \n                                              class_weight='balanced',\n                                              n_estimators=200,\n                                              max_depth=5),\n        'SVM': SVC(random_state=42, \n                   class_weight='balanced',\n                   kernel='rbf',",
        "detail": ".history.synapse_classification_20250223190906",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190906",
        "description": ".history.synapse_classification_20250223190906",
        "peekOfCode": "def plot_results(results, confusion_matrices):\n    \"\"\"Plot cross validation results and confusion matrices\"\"\"\n    n_classifiers = len(results)\n    fig, axes = plt.subplots(2, n_classifiers, figsize=(15, 10))\n    # Plot accuracy boxplots\n    axes[0, 1].boxplot(results.values(), labels=results.keys())\n    axes[0, 1].set_title('Classifier Performance Comparison')\n    axes[0, 1].set_ylabel('Accuracy')\n    axes[0, 1].set_xticklabels(results.keys(), rotation=45)\n    # Hide other plots in top row",
        "detail": ".history.synapse_classification_20250223190906",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190907",
        "description": ".history.synapse_classification_20250223190907",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Print class distribution to understand imbalance\n    print(\"\\nClass distribution:\")\n    print(df['pre_syn_clf_type'].value_counts())\n    # Select numerical features for classification\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types",
        "detail": ".history.synapse_classification_20250223190907",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190907",
        "description": ".history.synapse_classification_20250223190907",
        "peekOfCode": "def evaluate_classifiers(X, y, n_splits=5):\n    \"\"\"Evaluate multiple classifiers using k-fold cross validation\"\"\"\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42, \n                                              class_weight='balanced',\n                                              n_estimators=200,\n                                              max_depth=5),\n        'SVM': SVC(random_state=42, \n                   class_weight='balanced',\n                   kernel='rbf',",
        "detail": ".history.synapse_classification_20250223190907",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190907",
        "description": ".history.synapse_classification_20250223190907",
        "peekOfCode": "def plot_results(results, confusion_matrices):\n    \"\"\"Plot cross validation results and confusion matrices\"\"\"\n    n_classifiers = len(results)\n    fig, axes = plt.subplots(2, n_classifiers, figsize=(15, 10))\n    # Plot accuracy boxplots\n    axes[0, 1].boxplot(results.values(), labels=results.keys())\n    axes[0, 1].set_title('Classifier Performance Comparison')\n    axes[0, 1].set_ylabel('Accuracy')\n    axes[0, 1].set_xticklabels(results.keys(), rotation=45)\n    # Hide other plots in top row",
        "detail": ".history.synapse_classification_20250223190907",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190908",
        "description": ".history.synapse_classification_20250223190908",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Print class distribution to understand imbalance\n    print(\"\\nClass distribution:\")\n    print(df['pre_syn_clf_type'].value_counts())\n    # Select numerical features for classification\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types",
        "detail": ".history.synapse_classification_20250223190908",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190908",
        "description": ".history.synapse_classification_20250223190908",
        "peekOfCode": "def evaluate_classifiers(X, y, n_splits=5):\n    \"\"\"Evaluate multiple classifiers using k-fold cross validation\"\"\"\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42, \n                                              class_weight='balanced',\n                                              n_estimators=200,\n                                              max_depth=5),\n        'SVM': SVC(random_state=42, \n                   class_weight='balanced',\n                   kernel='rbf',",
        "detail": ".history.synapse_classification_20250223190908",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223190908",
        "description": ".history.synapse_classification_20250223190908",
        "peekOfCode": "def plot_results(results, confusion_matrices):\n    \"\"\"Plot cross validation results and confusion matrices\"\"\"\n    n_classifiers = len(results)\n    fig, axes = plt.subplots(2, n_classifiers, figsize=(15, 10))\n    # Plot accuracy boxplots\n    axes[0, 1].boxplot(results.values(), labels=results.keys())\n    axes[0, 1].set_title('Classifier Performance Comparison')\n    axes[0, 1].set_ylabel('Accuracy')\n    axes[0, 1].set_xticklabels(results.keys(), rotation=45)\n    # Hide other plots in top row",
        "detail": ".history.synapse_classification_20250223190908",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191115",
        "description": ".history.synapse_classification_20250223191115",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Print class distribution to understand imbalance\n    print(\"\\nClass distribution:\")\n    print(df['pre_syn_clf_type'].value_counts())\n    # Select numerical features for classification\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types",
        "detail": ".history.synapse_classification_20250223191115",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191115",
        "description": ".history.synapse_classification_20250223191115",
        "peekOfCode": "def evaluate_classifiers(X, y, n_splits=5):\n    \"\"\"Evaluate multiple classifiers using k-fold cross validation\"\"\"\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42, \n                                              n_estimators=200,\n                                              max_depth=5),\n        'SVM': SVC(random_state=42, \n                   kernel='rbf',\n                   probability=True),\n        'Neural Net': MLPClassifier(random_state=42,",
        "detail": ".history.synapse_classification_20250223191115",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191115",
        "description": ".history.synapse_classification_20250223191115",
        "peekOfCode": "def plot_results(results, confusion_matrices):\n    \"\"\"Plot cross validation results and confusion matrices\"\"\"\n    n_classifiers = len(results)\n    fig, axes = plt.subplots(2, n_classifiers, figsize=(15, 10))\n    # Plot accuracy boxplots\n    axes[0, 1].boxplot(results.values(), labels=results.keys())\n    axes[0, 1].set_title('Classifier Performance Comparison')\n    axes[0, 1].set_ylabel('Accuracy')\n    axes[0, 1].set_xticklabels(results.keys(), rotation=45)\n    # Hide other plots in top row",
        "detail": ".history.synapse_classification_20250223191115",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191116",
        "description": ".history.synapse_classification_20250223191116",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Print class distribution to understand imbalance\n    print(\"\\nClass distribution:\")\n    print(df['pre_syn_clf_type'].value_counts())\n    # Select numerical features for classification\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types",
        "detail": ".history.synapse_classification_20250223191116",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191116",
        "description": ".history.synapse_classification_20250223191116",
        "peekOfCode": "def evaluate_classifiers(X, y, n_splits=5):\n    \"\"\"Evaluate multiple classifiers using k-fold cross validation\"\"\"\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42, \n                                              n_estimators=200,\n                                              max_depth=5),\n        'SVM': SVC(random_state=42, \n                   kernel='rbf',\n                   probability=True),\n        'Neural Net': MLPClassifier(random_state=42,",
        "detail": ".history.synapse_classification_20250223191116",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191116",
        "description": ".history.synapse_classification_20250223191116",
        "peekOfCode": "def plot_results(results, confusion_matrices):\n    \"\"\"Plot cross validation results and confusion matrices\"\"\"\n    n_classifiers = len(results)\n    fig, axes = plt.subplots(2, n_classifiers, figsize=(15, 10))\n    # Plot accuracy boxplots\n    axes[0, 1].boxplot(results.values(), labels=results.keys())\n    axes[0, 1].set_title('Classifier Performance Comparison')\n    axes[0, 1].set_ylabel('Accuracy')\n    axes[0, 1].set_xticklabels(results.keys(), rotation=45)\n    # Hide other plots in top row",
        "detail": ".history.synapse_classification_20250223191116",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191227",
        "description": ".history.synapse_classification_20250223191227",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Print class distribution to understand imbalance\n    print(\"\\nClass distribution:\")\n    print(df['pre_syn_clf_type'].value_counts())\n    # Select numerical features for classification\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types",
        "detail": ".history.synapse_classification_20250223191227",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191227",
        "description": ".history.synapse_classification_20250223191227",
        "peekOfCode": "def evaluate_classifiers(X, y, n_splits=5):\n    \"\"\"Evaluate multiple classifiers using k-fold cross validation\"\"\"\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42, \n                                              n_estimators=200,\n                                              max_depth=5),\n        'SVM': SVC(random_state=42, \n                   kernel='rbf',\n                   probability=True),\n        'Neural Net': MLPClassifier(random_state=42,",
        "detail": ".history.synapse_classification_20250223191227",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191227",
        "description": ".history.synapse_classification_20250223191227",
        "peekOfCode": "def plot_results(results, confusion_matrices):\n    \"\"\"Plot cross validation results and confusion matrices\"\"\"\n    n_classifiers = len(results)\n    fig, axes = plt.subplots(2, n_classifiers, figsize=(15, 10))\n    # Plot accuracy boxplots\n    axes[0, 1].boxplot(results.values(), labels=results.keys())\n    axes[0, 1].set_title('Classifier Performance Comparison')\n    axes[0, 1].set_ylabel('Accuracy')\n    axes[0, 1].set_xticklabels(results.keys(), rotation=45)\n    # Hide other plots in top row",
        "detail": ".history.synapse_classification_20250223191227",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191228",
        "description": ".history.synapse_classification_20250223191228",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Print class distribution to understand imbalance\n    print(\"\\nClass distribution:\")\n    print(df['pre_syn_clf_type'].value_counts())\n    # Select numerical features for classification\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types",
        "detail": ".history.synapse_classification_20250223191228",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191228",
        "description": ".history.synapse_classification_20250223191228",
        "peekOfCode": "def evaluate_classifiers(X, y, n_splits=5):\n    \"\"\"Evaluate multiple classifiers using k-fold cross validation\"\"\"\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42, \n                                              n_estimators=200,\n                                              max_depth=5),\n        'SVM': SVC(random_state=42, \n                   kernel='rbf',\n                   probability=True),\n        'Neural Net': MLPClassifier(random_state=42,",
        "detail": ".history.synapse_classification_20250223191228",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191228",
        "description": ".history.synapse_classification_20250223191228",
        "peekOfCode": "def plot_results(results, confusion_matrices):\n    \"\"\"Plot cross validation results and confusion matrices\"\"\"\n    n_classifiers = len(results)\n    fig, axes = plt.subplots(2, n_classifiers, figsize=(15, 10))\n    # Plot accuracy boxplots\n    axes[0, 1].boxplot(results.values(), labels=results.keys())\n    axes[0, 1].set_title('Classifier Performance Comparison')\n    axes[0, 1].set_ylabel('Accuracy')\n    axes[0, 1].set_xticklabels(results.keys(), rotation=45)\n    # Hide other plots in top row",
        "detail": ".history.synapse_classification_20250223191228",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191406",
        "description": ".history.synapse_classification_20250223191406",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Print class distribution to understand imbalance\n    print(\"\\nClass distribution:\")\n    print(df['pre_syn_clf_type'].value_counts())\n    # Select numerical features for classification\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types",
        "detail": ".history.synapse_classification_20250223191406",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191406",
        "description": ".history.synapse_classification_20250223191406",
        "peekOfCode": "def evaluate_classifiers(X, y, n_splits=5):\n    \"\"\"Evaluate multiple classifiers using k-fold cross validation\"\"\"\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42, \n                                              n_estimators=500,\n                                              max_depth=10,\n                                              min_samples_leaf=5),\n        'SVM': SVC(random_state=42, \n                   kernel='rbf',\n                   C=10,",
        "detail": ".history.synapse_classification_20250223191406",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191406",
        "description": ".history.synapse_classification_20250223191406",
        "peekOfCode": "def plot_results(results, confusion_matrices):\n    \"\"\"Plot cross validation results and confusion matrices\"\"\"\n    n_classifiers = len(results)\n    fig, axes = plt.subplots(2, n_classifiers, figsize=(15, 10))\n    # Plot accuracy boxplots\n    axes[0, 1].boxplot(results.values(), labels=results.keys())\n    axes[0, 1].set_title('Classifier Performance Comparison')\n    axes[0, 1].set_ylabel('Accuracy')\n    axes[0, 1].set_xticklabels(results.keys(), rotation=45)\n    # Hide other plots in top row",
        "detail": ".history.synapse_classification_20250223191406",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191407",
        "description": ".history.synapse_classification_20250223191407",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Print class distribution to understand imbalance\n    print(\"\\nClass distribution:\")\n    print(df['pre_syn_clf_type'].value_counts())\n    # Select numerical features for classification\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types",
        "detail": ".history.synapse_classification_20250223191407",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191407",
        "description": ".history.synapse_classification_20250223191407",
        "peekOfCode": "def evaluate_classifiers(X, y, n_splits=5):\n    \"\"\"Evaluate multiple classifiers using k-fold cross validation\"\"\"\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42, \n                                              n_estimators=500,\n                                              max_depth=10,\n                                              min_samples_leaf=5),\n        'SVM': SVC(random_state=42, \n                   kernel='rbf',\n                   C=10,",
        "detail": ".history.synapse_classification_20250223191407",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191407",
        "description": ".history.synapse_classification_20250223191407",
        "peekOfCode": "def plot_results(results, confusion_matrices):\n    \"\"\"Plot cross validation results and confusion matrices\"\"\"\n    n_classifiers = len(results)\n    fig, axes = plt.subplots(2, n_classifiers, figsize=(15, 10))\n    # Plot accuracy boxplots\n    axes[0, 1].boxplot(results.values(), labels=results.keys())\n    axes[0, 1].set_title('Classifier Performance Comparison')\n    axes[0, 1].set_ylabel('Accuracy')\n    axes[0, 1].set_xticklabels(results.keys(), rotation=45)\n    # Hide other plots in top row",
        "detail": ".history.synapse_classification_20250223191407",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191606",
        "description": ".history.synapse_classification_20250223191606",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Print class distribution to understand imbalance\n    print(\"\\nClass distribution:\")\n    print(df['pre_syn_clf_type'].value_counts())\n    # Select numerical features for classification\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types",
        "detail": ".history.synapse_classification_20250223191606",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191606",
        "description": ".history.synapse_classification_20250223191606",
        "peekOfCode": "def evaluate_classifiers(X, y, n_splits=5):\n    \"\"\"Evaluate multiple classifiers using k-fold cross validation\"\"\"\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42, \n                                              n_estimators=500,\n                                              max_depth=10,\n                                              min_samples_leaf=5),\n        'SVM': SVC(random_state=42, \n                   kernel='rbf',\n                   C=10,",
        "detail": ".history.synapse_classification_20250223191606",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191606",
        "description": ".history.synapse_classification_20250223191606",
        "peekOfCode": "def plot_results(results, confusion_matrices):\n    \"\"\"Plot cross validation results and confusion matrices\"\"\"\n    n_classifiers = len(results)\n    fig, axes = plt.subplots(2, n_classifiers, figsize=(15, 10))\n    # Plot accuracy boxplots\n    axes[0, 1].boxplot(results.values(), labels=results.keys())\n    axes[0, 1].set_title('Classifier Performance Comparison')\n    axes[0, 1].set_ylabel('Accuracy')\n    axes[0, 1].set_xticklabels(results.keys(), rotation=45)\n    # Hide other plots in top row",
        "detail": ".history.synapse_classification_20250223191606",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191936",
        "description": ".history.synapse_classification_20250223191936",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Print class distribution to understand imbalance\n    print(\"\\nClass distribution:\")\n    print(df['pre_syn_clf_type'].value_counts())\n    # Select numerical features for classification\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types",
        "detail": ".history.synapse_classification_20250223191936",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191936",
        "description": ".history.synapse_classification_20250223191936",
        "peekOfCode": "def evaluate_classifiers(X, y, n_splits=5):\n    \"\"\"Evaluate multiple classifiers using k-fold cross validation\"\"\"\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42, \n                                              n_estimators=500,\n                                              max_depth=10,\n                                              min_samples_leaf=5),\n        'SVM': SVC(random_state=42, \n                   kernel='rbf',\n                   C=10,",
        "detail": ".history.synapse_classification_20250223191936",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223191936",
        "description": ".history.synapse_classification_20250223191936",
        "peekOfCode": "def plot_results(results, confusion_matrices):\n    \"\"\"Plot cross validation results and confusion matrices\"\"\"\n    n_classifiers = len(results)\n    fig, axes = plt.subplots(2, n_classifiers, figsize=(15, 10))\n    # Plot accuracy boxplots\n    axes[0, 1].boxplot(results.values(), labels=results.keys())\n    axes[0, 1].set_title('Classifier Performance Comparison')\n    axes[0, 1].set_ylabel('Accuracy')\n    axes[0, 1].set_xticklabels(results.keys(), rotation=45)\n    # Hide other plots in top row",
        "detail": ".history.synapse_classification_20250223191936",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223192034",
        "description": ".history.synapse_classification_20250223192034",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Print class distribution to understand imbalance\n    print(\"\\nClass distribution:\")\n    print(df['pre_syn_clf_type'].value_counts())\n    # Select numerical features for classification\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types",
        "detail": ".history.synapse_classification_20250223192034",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223192034",
        "description": ".history.synapse_classification_20250223192034",
        "peekOfCode": "def evaluate_classifiers(X, y):\n    \"\"\"Evaluate classifiers on full dataset with balanced training\"\"\"\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42, \n                                              n_estimators=500,\n                                              max_depth=10,\n                                              min_samples_leaf=5),\n        'SVM': SVC(random_state=42, \n                   kernel='rbf',\n                   C=10,",
        "detail": ".history.synapse_classification_20250223192034",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223192034",
        "description": ".history.synapse_classification_20250223192034",
        "peekOfCode": "def plot_results(results, confusion_matrices):\n    \"\"\"Plot confusion matrices as fractions\"\"\"\n    n_classifiers = len(confusion_matrices)\n    fig, axes = plt.subplots(1, n_classifiers, figsize=(15, 5))\n    # Plot confusion matrices\n    labels = ['I', 'E']\n    for idx, (name, cm) in enumerate(confusion_matrices.items()):\n        sns.heatmap(cm, annot=True, fmt='.3f', cmap='Blues', ax=axes[idx],\n                   xticklabels=labels, yticklabels=labels, vmin=0, vmax=1)\n        axes[idx].set_title(f'{name}\\nAccuracy: {results[name]:.3f}')",
        "detail": ".history.synapse_classification_20250223192034",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223192035",
        "description": ".history.synapse_classification_20250223192035",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Print class distribution to understand imbalance\n    print(\"\\nClass distribution:\")\n    print(df['pre_syn_clf_type'].value_counts())\n    # Select numerical features for classification\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types",
        "detail": ".history.synapse_classification_20250223192035",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223192035",
        "description": ".history.synapse_classification_20250223192035",
        "peekOfCode": "def evaluate_classifiers(X, y):\n    \"\"\"Evaluate classifiers on full dataset with balanced training\"\"\"\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42, \n                                              n_estimators=500,\n                                              max_depth=10,\n                                              min_samples_leaf=5),\n        'SVM': SVC(random_state=42, \n                   kernel='rbf',\n                   C=10,",
        "detail": ".history.synapse_classification_20250223192035",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": ".history.synapse_classification_20250223192035",
        "description": ".history.synapse_classification_20250223192035",
        "peekOfCode": "def plot_results(results, confusion_matrices):\n    \"\"\"Plot confusion matrices as fractions\"\"\"\n    n_classifiers = len(confusion_matrices)\n    fig, axes = plt.subplots(1, n_classifiers, figsize=(15, 5))\n    # Plot confusion matrices\n    labels = ['I', 'E']\n    for idx, (name, cm) in enumerate(confusion_matrices.items()):\n        sns.heatmap(cm, annot=True, fmt='.3f', cmap='Blues', ax=axes[idx],\n                   xticklabels=labels, yticklabels=labels, vmin=0, vmax=1)\n        axes[idx].set_title(f'{name}\\nAccuracy: {results[name]:.3f}')",
        "detail": ".history.synapse_classification_20250223192035",
        "documentation": {}
    },
    {
        "label": "calculate_synapse_metrics",
        "kind": 2,
        "importPath": ".history.synapse_metrics_20250223170116",
        "description": ".history.synapse_metrics_20250223170116",
        "peekOfCode": "def calculate_synapse_metrics(synapses, path_):\n    metrics_data = []\n    for _, row in synapses.iterrows():\n        syn_id = row['syn_id']\n        img = np.load(f'{path_}{syn_id}_syn.npy')\n        pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\n        post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n        size_metrics = synapse_size(pre_mask, post_mask)\n        shape_metrics = synapse_shape(pre_mask, post_mask)\n        intensity_metrics = synapse_intensity(img, pre_mask, post_mask)",
        "detail": ".history.synapse_metrics_20250223170116",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170116",
        "description": ".history.synapse_metrics_20250223170116",
        "peekOfCode": "path_ = '../data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nmetrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170116",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170116",
        "description": ".history.synapse_metrics_20250223170116",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nmetrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170116",
        "documentation": {}
    },
    {
        "label": "metrics_df",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170116",
        "description": ".history.synapse_metrics_20250223170116",
        "peekOfCode": "metrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170116",
        "documentation": {}
    },
    {
        "label": "synapses_with_metrics",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170116",
        "description": ".history.synapse_metrics_20250223170116",
        "peekOfCode": "synapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170116",
        "documentation": {}
    },
    {
        "label": "calculate_synapse_metrics",
        "kind": 2,
        "importPath": ".history.synapse_metrics_20250223170118",
        "description": ".history.synapse_metrics_20250223170118",
        "peekOfCode": "def calculate_synapse_metrics(synapses, path_):\n    metrics_data = []\n    for _, row in synapses.iterrows():\n        syn_id = row['syn_id']\n        img = np.load(f'{path_}{syn_id}_syn.npy')\n        pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\n        post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n        size_metrics = synapse_size(pre_mask, post_mask)\n        shape_metrics = synapse_shape(pre_mask, post_mask)\n        intensity_metrics = synapse_intensity(img, pre_mask, post_mask)",
        "detail": ".history.synapse_metrics_20250223170118",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170118",
        "description": ".history.synapse_metrics_20250223170118",
        "peekOfCode": "path_ = '../data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nmetrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170118",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170118",
        "description": ".history.synapse_metrics_20250223170118",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nmetrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170118",
        "documentation": {}
    },
    {
        "label": "metrics_df",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170118",
        "description": ".history.synapse_metrics_20250223170118",
        "peekOfCode": "metrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170118",
        "documentation": {}
    },
    {
        "label": "synapses_with_metrics",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170118",
        "description": ".history.synapse_metrics_20250223170118",
        "peekOfCode": "synapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170118",
        "documentation": {}
    },
    {
        "label": "calculate_synapse_metrics",
        "kind": 2,
        "importPath": ".history.synapse_metrics_20250223170147",
        "description": ".history.synapse_metrics_20250223170147",
        "peekOfCode": "def calculate_synapse_metrics(synapses, path_):\n    metrics_data = []\n    for _, row in synapses.iterrows():\n        syn_id = row['syn_id']\n        img = np.load(f'{path_}{syn_id}_syn.npy')\n        pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\n        post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n        size_metrics = synapse_size(pre_mask, post_mask)\n        shape_metrics = synapse_shape(pre_mask, post_mask)\n        intensity_metrics = synapse_intensity(img, pre_mask, post_mask)",
        "detail": ".history.synapse_metrics_20250223170147",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170147",
        "description": ".history.synapse_metrics_20250223170147",
        "peekOfCode": "path_ = '../data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data_metrics.csv', index_col=0)\nmetrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170147",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170147",
        "description": ".history.synapse_metrics_20250223170147",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data_metrics.csv', index_col=0)\nmetrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170147",
        "documentation": {}
    },
    {
        "label": "metrics_df",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170147",
        "description": ".history.synapse_metrics_20250223170147",
        "peekOfCode": "metrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170147",
        "documentation": {}
    },
    {
        "label": "synapses_with_metrics",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170147",
        "description": ".history.synapse_metrics_20250223170147",
        "peekOfCode": "synapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170147",
        "documentation": {}
    },
    {
        "label": "calculate_synapse_metrics",
        "kind": 2,
        "importPath": ".history.synapse_metrics_20250223170700",
        "description": ".history.synapse_metrics_20250223170700",
        "peekOfCode": "def calculate_synapse_metrics(synapses, path_):\n    metrics_data = []\n    for _, row in synapses.iterrows():\n        syn_id = row['syn_id']\n        img = np.load(f'{path_}{syn_id}_syn.npy')\n        pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\n        post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n        size_metrics = synapse_size(pre_mask, post_mask)\n        shape_metrics = synapse_shape(pre_mask, post_mask)\n        intensity_metrics = synapse_intensity(img, pre_mask, post_mask)",
        "detail": ".history.synapse_metrics_20250223170700",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170700",
        "description": ".history.synapse_metrics_20250223170700",
        "peekOfCode": "path_ = 'data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data_metrics.csv', index_col=0)\nmetrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170700",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170700",
        "description": ".history.synapse_metrics_20250223170700",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data_metrics.csv', index_col=0)\nmetrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170700",
        "documentation": {}
    },
    {
        "label": "metrics_df",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170700",
        "description": ".history.synapse_metrics_20250223170700",
        "peekOfCode": "metrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170700",
        "documentation": {}
    },
    {
        "label": "synapses_with_metrics",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170700",
        "description": ".history.synapse_metrics_20250223170700",
        "peekOfCode": "synapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170700",
        "documentation": {}
    },
    {
        "label": "calculate_synapse_metrics",
        "kind": 2,
        "importPath": ".history.synapse_metrics_20250223170701",
        "description": ".history.synapse_metrics_20250223170701",
        "peekOfCode": "def calculate_synapse_metrics(synapses, path_):\n    metrics_data = []\n    for _, row in synapses.iterrows():\n        syn_id = row['syn_id']\n        img = np.load(f'{path_}{syn_id}_syn.npy')\n        pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\n        post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n        size_metrics = synapse_size(pre_mask, post_mask)\n        shape_metrics = synapse_shape(pre_mask, post_mask)\n        intensity_metrics = synapse_intensity(img, pre_mask, post_mask)",
        "detail": ".history.synapse_metrics_20250223170701",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170701",
        "description": ".history.synapse_metrics_20250223170701",
        "peekOfCode": "path_ = 'data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data_metrics.csv', index_col=0)\nmetrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170701",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170701",
        "description": ".history.synapse_metrics_20250223170701",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data_metrics.csv', index_col=0)\nmetrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170701",
        "documentation": {}
    },
    {
        "label": "metrics_df",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170701",
        "description": ".history.synapse_metrics_20250223170701",
        "peekOfCode": "metrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170701",
        "documentation": {}
    },
    {
        "label": "synapses_with_metrics",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170701",
        "description": ".history.synapse_metrics_20250223170701",
        "peekOfCode": "synapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170701",
        "documentation": {}
    },
    {
        "label": "calculate_synapse_metrics",
        "kind": 2,
        "importPath": ".history.synapse_metrics_20250223170717",
        "description": ".history.synapse_metrics_20250223170717",
        "peekOfCode": "def calculate_synapse_metrics(synapses, path_):\n    metrics_data = []\n    for _, row in synapses.iterrows():\n        syn_id = row['syn_id']\n        img = np.load(f'{path_}{syn_id}_syn.npy')\n        pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\n        post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n        size_metrics = synapse_size(pre_mask, post_mask)\n        shape_metrics = synapse_shape(pre_mask, post_mask)\n        intensity_metrics = synapse_intensity(img, pre_mask, post_mask)",
        "detail": ".history.synapse_metrics_20250223170717",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170717",
        "description": ".history.synapse_metrics_20250223170717",
        "peekOfCode": "path_ = 'data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nmetrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170717",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170717",
        "description": ".history.synapse_metrics_20250223170717",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nmetrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170717",
        "documentation": {}
    },
    {
        "label": "metrics_df",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170717",
        "description": ".history.synapse_metrics_20250223170717",
        "peekOfCode": "metrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170717",
        "documentation": {}
    },
    {
        "label": "synapses_with_metrics",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170717",
        "description": ".history.synapse_metrics_20250223170717",
        "peekOfCode": "synapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170717",
        "documentation": {}
    },
    {
        "label": "calculate_synapse_metrics",
        "kind": 2,
        "importPath": ".history.synapse_metrics_20250223170758",
        "description": ".history.synapse_metrics_20250223170758",
        "peekOfCode": "def calculate_synapse_metrics(synapses, path_):\n    metrics_data = []\n    for i, row in synapses.iterrows():\n        print(i)\n        syn_id = row['syn_id']\n        img = np.load(f'{path_}{syn_id}_syn.npy')\n        pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\n        post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n        size_metrics = synapse_size(pre_mask, post_mask)\n        shape_metrics = synapse_shape(pre_mask, post_mask)",
        "detail": ".history.synapse_metrics_20250223170758",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170758",
        "description": ".history.synapse_metrics_20250223170758",
        "peekOfCode": "path_ = 'data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nmetrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170758",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170758",
        "description": ".history.synapse_metrics_20250223170758",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nmetrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170758",
        "documentation": {}
    },
    {
        "label": "metrics_df",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170758",
        "description": ".history.synapse_metrics_20250223170758",
        "peekOfCode": "metrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170758",
        "documentation": {}
    },
    {
        "label": "synapses_with_metrics",
        "kind": 5,
        "importPath": ".history.synapse_metrics_20250223170758",
        "description": ".history.synapse_metrics_20250223170758",
        "peekOfCode": "synapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": ".history.synapse_metrics_20250223170758",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160809",
        "description": ".history.Syn_props_20250223160809",
        "peekOfCode": "path_ = '../data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223160809",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160809",
        "description": ".history.Syn_props_20250223160809",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223160809",
        "documentation": {}
    },
    {
        "label": "syn_id",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160809",
        "description": ".history.Syn_props_20250223160809",
        "peekOfCode": "syn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160809",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160809",
        "description": ".history.Syn_props_20250223160809",
        "peekOfCode": "img = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160809",
        "documentation": {}
    },
    {
        "label": "pre_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160809",
        "description": ".history.Syn_props_20250223160809",
        "peekOfCode": "pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160809",
        "documentation": {}
    },
    {
        "label": "post_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160809",
        "description": ".history.Syn_props_20250223160809",
        "peekOfCode": "post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160809",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160829",
        "description": ".history.Syn_props_20250223160829",
        "peekOfCode": "path_ = '../data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223160829",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160829",
        "description": ".history.Syn_props_20250223160829",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223160829",
        "documentation": {}
    },
    {
        "label": "syn_id",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160829",
        "description": ".history.Syn_props_20250223160829",
        "peekOfCode": "syn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160829",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160829",
        "description": ".history.Syn_props_20250223160829",
        "peekOfCode": "img = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160829",
        "documentation": {}
    },
    {
        "label": "pre_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160829",
        "description": ".history.Syn_props_20250223160829",
        "peekOfCode": "pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160829",
        "documentation": {}
    },
    {
        "label": "post_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160829",
        "description": ".history.Syn_props_20250223160829",
        "peekOfCode": "post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160829",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160909",
        "description": ".history.Syn_props_20250223160909",
        "peekOfCode": "path_ = '../data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223160909",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160909",
        "description": ".history.Syn_props_20250223160909",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223160909",
        "documentation": {}
    },
    {
        "label": "syn_id",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160909",
        "description": ".history.Syn_props_20250223160909",
        "peekOfCode": "syn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223160909",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160909",
        "description": ".history.Syn_props_20250223160909",
        "peekOfCode": "img = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))",
        "detail": ".history.Syn_props_20250223160909",
        "documentation": {}
    },
    {
        "label": "pre_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160909",
        "description": ".history.Syn_props_20250223160909",
        "peekOfCode": "pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223160909",
        "documentation": {}
    },
    {
        "label": "post_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160909",
        "description": ".history.Syn_props_20250223160909",
        "peekOfCode": "post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223160909",
        "documentation": {}
    },
    {
        "label": "size_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160909",
        "description": ".history.Syn_props_20250223160909",
        "peekOfCode": "size_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)",
        "detail": ".history.Syn_props_20250223160909",
        "documentation": {}
    },
    {
        "label": "shape_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160909",
        "description": ".history.Syn_props_20250223160909",
        "peekOfCode": "shape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)",
        "detail": ".history.Syn_props_20250223160909",
        "documentation": {}
    },
    {
        "label": "intensity_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160909",
        "description": ".history.Syn_props_20250223160909",
        "peekOfCode": "intensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160909",
        "documentation": {}
    },
    {
        "label": "distance",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160909",
        "description": ".history.Syn_props_20250223160909",
        "peekOfCode": "distance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160909",
        "documentation": {}
    },
    {
        "label": "coloc_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160909",
        "description": ".history.Syn_props_20250223160909",
        "peekOfCode": "coloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160909",
        "documentation": {}
    },
    {
        "label": "morphology_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160909",
        "description": ".history.Syn_props_20250223160909",
        "peekOfCode": "morphology_metrics = synapse_morphology(pre_mask, post_mask)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160909",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160938",
        "description": ".history.Syn_props_20250223160938",
        "peekOfCode": "path_ = '../data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223160938",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160938",
        "description": ".history.Syn_props_20250223160938",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223160938",
        "documentation": {}
    },
    {
        "label": "syn_id",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160938",
        "description": ".history.Syn_props_20250223160938",
        "peekOfCode": "syn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) ",
        "detail": ".history.Syn_props_20250223160938",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160938",
        "description": ".history.Syn_props_20250223160938",
        "peekOfCode": "img = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))",
        "detail": ".history.Syn_props_20250223160938",
        "documentation": {}
    },
    {
        "label": "pre_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160938",
        "description": ".history.Syn_props_20250223160938",
        "peekOfCode": "pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223160938",
        "documentation": {}
    },
    {
        "label": "post_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160938",
        "description": ".history.Syn_props_20250223160938",
        "peekOfCode": "post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223160938",
        "documentation": {}
    },
    {
        "label": "size_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160938",
        "description": ".history.Syn_props_20250223160938",
        "peekOfCode": "size_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)",
        "detail": ".history.Syn_props_20250223160938",
        "documentation": {}
    },
    {
        "label": "shape_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160938",
        "description": ".history.Syn_props_20250223160938",
        "peekOfCode": "shape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)",
        "detail": ".history.Syn_props_20250223160938",
        "documentation": {}
    },
    {
        "label": "intensity_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160938",
        "description": ".history.Syn_props_20250223160938",
        "peekOfCode": "intensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160938",
        "documentation": {}
    },
    {
        "label": "distance",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160938",
        "description": ".history.Syn_props_20250223160938",
        "peekOfCode": "distance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160938",
        "documentation": {}
    },
    {
        "label": "coloc_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160938",
        "description": ".history.Syn_props_20250223160938",
        "peekOfCode": "coloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160938",
        "documentation": {}
    },
    {
        "label": "morphology_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160938",
        "description": ".history.Syn_props_20250223160938",
        "peekOfCode": "morphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160938",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160939",
        "description": ".history.Syn_props_20250223160939",
        "peekOfCode": "path_ = '../data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223160939",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160939",
        "description": ".history.Syn_props_20250223160939",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223160939",
        "documentation": {}
    },
    {
        "label": "syn_id",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160939",
        "description": ".history.Syn_props_20250223160939",
        "peekOfCode": "syn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) ",
        "detail": ".history.Syn_props_20250223160939",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160939",
        "description": ".history.Syn_props_20250223160939",
        "peekOfCode": "img = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))",
        "detail": ".history.Syn_props_20250223160939",
        "documentation": {}
    },
    {
        "label": "pre_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160939",
        "description": ".history.Syn_props_20250223160939",
        "peekOfCode": "pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223160939",
        "documentation": {}
    },
    {
        "label": "post_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160939",
        "description": ".history.Syn_props_20250223160939",
        "peekOfCode": "post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223160939",
        "documentation": {}
    },
    {
        "label": "size_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160939",
        "description": ".history.Syn_props_20250223160939",
        "peekOfCode": "size_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)",
        "detail": ".history.Syn_props_20250223160939",
        "documentation": {}
    },
    {
        "label": "shape_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160939",
        "description": ".history.Syn_props_20250223160939",
        "peekOfCode": "shape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)",
        "detail": ".history.Syn_props_20250223160939",
        "documentation": {}
    },
    {
        "label": "intensity_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160939",
        "description": ".history.Syn_props_20250223160939",
        "peekOfCode": "intensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160939",
        "documentation": {}
    },
    {
        "label": "distance",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160939",
        "description": ".history.Syn_props_20250223160939",
        "peekOfCode": "distance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160939",
        "documentation": {}
    },
    {
        "label": "coloc_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160939",
        "description": ".history.Syn_props_20250223160939",
        "peekOfCode": "coloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160939",
        "documentation": {}
    },
    {
        "label": "morphology_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160939",
        "description": ".history.Syn_props_20250223160939",
        "peekOfCode": "morphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160939",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160947",
        "description": ".history.Syn_props_20250223160947",
        "peekOfCode": "path_ = '../data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223160947",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160947",
        "description": ".history.Syn_props_20250223160947",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223160947",
        "documentation": {}
    },
    {
        "label": "syn_id",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160947",
        "description": ".history.Syn_props_20250223160947",
        "peekOfCode": "syn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) ",
        "detail": ".history.Syn_props_20250223160947",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160947",
        "description": ".history.Syn_props_20250223160947",
        "peekOfCode": "img = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))",
        "detail": ".history.Syn_props_20250223160947",
        "documentation": {}
    },
    {
        "label": "pre_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160947",
        "description": ".history.Syn_props_20250223160947",
        "peekOfCode": "pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223160947",
        "documentation": {}
    },
    {
        "label": "post_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160947",
        "description": ".history.Syn_props_20250223160947",
        "peekOfCode": "post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223160947",
        "documentation": {}
    },
    {
        "label": "size_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160947",
        "description": ".history.Syn_props_20250223160947",
        "peekOfCode": "size_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)",
        "detail": ".history.Syn_props_20250223160947",
        "documentation": {}
    },
    {
        "label": "shape_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160947",
        "description": ".history.Syn_props_20250223160947",
        "peekOfCode": "shape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)",
        "detail": ".history.Syn_props_20250223160947",
        "documentation": {}
    },
    {
        "label": "intensity_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160947",
        "description": ".history.Syn_props_20250223160947",
        "peekOfCode": "intensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160947",
        "documentation": {}
    },
    {
        "label": "distance",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160947",
        "description": ".history.Syn_props_20250223160947",
        "peekOfCode": "distance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160947",
        "documentation": {}
    },
    {
        "label": "coloc_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160947",
        "description": ".history.Syn_props_20250223160947",
        "peekOfCode": "coloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160947",
        "documentation": {}
    },
    {
        "label": "morphology_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160947",
        "description": ".history.Syn_props_20250223160947",
        "peekOfCode": "morphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160947",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160949",
        "description": ".history.Syn_props_20250223160949",
        "peekOfCode": "path_ = '../data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223160949",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160949",
        "description": ".history.Syn_props_20250223160949",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223160949",
        "documentation": {}
    },
    {
        "label": "syn_id",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160949",
        "description": ".history.Syn_props_20250223160949",
        "peekOfCode": "syn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) ",
        "detail": ".history.Syn_props_20250223160949",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160949",
        "description": ".history.Syn_props_20250223160949",
        "peekOfCode": "img = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))",
        "detail": ".history.Syn_props_20250223160949",
        "documentation": {}
    },
    {
        "label": "pre_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160949",
        "description": ".history.Syn_props_20250223160949",
        "peekOfCode": "pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223160949",
        "documentation": {}
    },
    {
        "label": "post_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160949",
        "description": ".history.Syn_props_20250223160949",
        "peekOfCode": "post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223160949",
        "documentation": {}
    },
    {
        "label": "size_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160949",
        "description": ".history.Syn_props_20250223160949",
        "peekOfCode": "size_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)",
        "detail": ".history.Syn_props_20250223160949",
        "documentation": {}
    },
    {
        "label": "shape_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160949",
        "description": ".history.Syn_props_20250223160949",
        "peekOfCode": "shape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)",
        "detail": ".history.Syn_props_20250223160949",
        "documentation": {}
    },
    {
        "label": "intensity_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160949",
        "description": ".history.Syn_props_20250223160949",
        "peekOfCode": "intensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160949",
        "documentation": {}
    },
    {
        "label": "distance",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160949",
        "description": ".history.Syn_props_20250223160949",
        "peekOfCode": "distance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160949",
        "documentation": {}
    },
    {
        "label": "coloc_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160949",
        "description": ".history.Syn_props_20250223160949",
        "peekOfCode": "coloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160949",
        "documentation": {}
    },
    {
        "label": "morphology_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223160949",
        "description": ".history.Syn_props_20250223160949",
        "peekOfCode": "morphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223160949",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162000",
        "description": ".history.Syn_props_20250223162000",
        "peekOfCode": "path_ = data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223162000",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162000",
        "description": ".history.Syn_props_20250223162000",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223162000",
        "documentation": {}
    },
    {
        "label": "syn_id",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162000",
        "description": ".history.Syn_props_20250223162000",
        "peekOfCode": "syn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) ",
        "detail": ".history.Syn_props_20250223162000",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162000",
        "description": ".history.Syn_props_20250223162000",
        "peekOfCode": "img = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))",
        "detail": ".history.Syn_props_20250223162000",
        "documentation": {}
    },
    {
        "label": "pre_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162000",
        "description": ".history.Syn_props_20250223162000",
        "peekOfCode": "pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223162000",
        "documentation": {}
    },
    {
        "label": "post_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162000",
        "description": ".history.Syn_props_20250223162000",
        "peekOfCode": "post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223162000",
        "documentation": {}
    },
    {
        "label": "size_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162000",
        "description": ".history.Syn_props_20250223162000",
        "peekOfCode": "size_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)",
        "detail": ".history.Syn_props_20250223162000",
        "documentation": {}
    },
    {
        "label": "shape_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162000",
        "description": ".history.Syn_props_20250223162000",
        "peekOfCode": "shape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)",
        "detail": ".history.Syn_props_20250223162000",
        "documentation": {}
    },
    {
        "label": "intensity_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162000",
        "description": ".history.Syn_props_20250223162000",
        "peekOfCode": "intensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223162000",
        "documentation": {}
    },
    {
        "label": "distance",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162000",
        "description": ".history.Syn_props_20250223162000",
        "peekOfCode": "distance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223162000",
        "documentation": {}
    },
    {
        "label": "coloc_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162000",
        "description": ".history.Syn_props_20250223162000",
        "peekOfCode": "coloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223162000",
        "documentation": {}
    },
    {
        "label": "morphology_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162000",
        "description": ".history.Syn_props_20250223162000",
        "peekOfCode": "morphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223162000",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162001",
        "description": ".history.Syn_props_20250223162001",
        "peekOfCode": "path_ = data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223162001",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162001",
        "description": ".history.Syn_props_20250223162001",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223162001",
        "documentation": {}
    },
    {
        "label": "syn_id",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162001",
        "description": ".history.Syn_props_20250223162001",
        "peekOfCode": "syn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) ",
        "detail": ".history.Syn_props_20250223162001",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162001",
        "description": ".history.Syn_props_20250223162001",
        "peekOfCode": "img = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))",
        "detail": ".history.Syn_props_20250223162001",
        "documentation": {}
    },
    {
        "label": "pre_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162001",
        "description": ".history.Syn_props_20250223162001",
        "peekOfCode": "pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223162001",
        "documentation": {}
    },
    {
        "label": "post_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162001",
        "description": ".history.Syn_props_20250223162001",
        "peekOfCode": "post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223162001",
        "documentation": {}
    },
    {
        "label": "size_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162001",
        "description": ".history.Syn_props_20250223162001",
        "peekOfCode": "size_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)",
        "detail": ".history.Syn_props_20250223162001",
        "documentation": {}
    },
    {
        "label": "shape_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162001",
        "description": ".history.Syn_props_20250223162001",
        "peekOfCode": "shape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)",
        "detail": ".history.Syn_props_20250223162001",
        "documentation": {}
    },
    {
        "label": "intensity_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162001",
        "description": ".history.Syn_props_20250223162001",
        "peekOfCode": "intensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223162001",
        "documentation": {}
    },
    {
        "label": "distance",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162001",
        "description": ".history.Syn_props_20250223162001",
        "peekOfCode": "distance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223162001",
        "documentation": {}
    },
    {
        "label": "coloc_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162001",
        "description": ".history.Syn_props_20250223162001",
        "peekOfCode": "coloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223162001",
        "documentation": {}
    },
    {
        "label": "morphology_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162001",
        "description": ".history.Syn_props_20250223162001",
        "peekOfCode": "morphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223162001",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162020",
        "description": ".history.Syn_props_20250223162020",
        "peekOfCode": "path_ = 'data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223162020",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162020",
        "description": ".history.Syn_props_20250223162020",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223162020",
        "documentation": {}
    },
    {
        "label": "syn_id",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162020",
        "description": ".history.Syn_props_20250223162020",
        "peekOfCode": "syn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) ",
        "detail": ".history.Syn_props_20250223162020",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162020",
        "description": ".history.Syn_props_20250223162020",
        "peekOfCode": "img = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))",
        "detail": ".history.Syn_props_20250223162020",
        "documentation": {}
    },
    {
        "label": "pre_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162020",
        "description": ".history.Syn_props_20250223162020",
        "peekOfCode": "pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223162020",
        "documentation": {}
    },
    {
        "label": "post_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162020",
        "description": ".history.Syn_props_20250223162020",
        "peekOfCode": "post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')",
        "detail": ".history.Syn_props_20250223162020",
        "documentation": {}
    },
    {
        "label": "size_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162020",
        "description": ".history.Syn_props_20250223162020",
        "peekOfCode": "size_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)",
        "detail": ".history.Syn_props_20250223162020",
        "documentation": {}
    },
    {
        "label": "shape_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162020",
        "description": ".history.Syn_props_20250223162020",
        "peekOfCode": "shape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)",
        "detail": ".history.Syn_props_20250223162020",
        "documentation": {}
    },
    {
        "label": "intensity_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162020",
        "description": ".history.Syn_props_20250223162020",
        "peekOfCode": "intensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223162020",
        "documentation": {}
    },
    {
        "label": "distance",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162020",
        "description": ".history.Syn_props_20250223162020",
        "peekOfCode": "distance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223162020",
        "documentation": {}
    },
    {
        "label": "coloc_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162020",
        "description": ".history.Syn_props_20250223162020",
        "peekOfCode": "coloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223162020",
        "documentation": {}
    },
    {
        "label": "morphology_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162020",
        "description": ".history.Syn_props_20250223162020",
        "peekOfCode": "morphology_metrics = synapse_morphology(pre_mask, post_mask) \nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223162020",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162426",
        "description": ".history.Syn_props_20250223162426",
        "peekOfCode": "path_ = 'data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223162426",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162426",
        "description": ".history.Syn_props_20250223162426",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223162426",
        "documentation": {}
    },
    {
        "label": "syn_id",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162426",
        "description": ".history.Syn_props_20250223162426",
        "peekOfCode": "syn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223162426",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162426",
        "description": ".history.Syn_props_20250223162426",
        "peekOfCode": "img = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223162426",
        "documentation": {}
    },
    {
        "label": "pre_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162426",
        "description": ".history.Syn_props_20250223162426",
        "peekOfCode": "pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics",
        "detail": ".history.Syn_props_20250223162426",
        "documentation": {}
    },
    {
        "label": "post_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162426",
        "description": ".history.Syn_props_20250223162426",
        "peekOfCode": "post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {",
        "detail": ".history.Syn_props_20250223162426",
        "documentation": {}
    },
    {
        "label": "size_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162426",
        "description": ".history.Syn_props_20250223162426",
        "peekOfCode": "size_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],",
        "detail": ".history.Syn_props_20250223162426",
        "documentation": {}
    },
    {
        "label": "shape_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162426",
        "description": ".history.Syn_props_20250223162426",
        "peekOfCode": "shape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],",
        "detail": ".history.Syn_props_20250223162426",
        "documentation": {}
    },
    {
        "label": "intensity_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162426",
        "description": ".history.Syn_props_20250223162426",
        "peekOfCode": "intensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],",
        "detail": ".history.Syn_props_20250223162426",
        "documentation": {}
    },
    {
        "label": "distance",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162426",
        "description": ".history.Syn_props_20250223162426",
        "peekOfCode": "distance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],",
        "detail": ".history.Syn_props_20250223162426",
        "documentation": {}
    },
    {
        "label": "coloc_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162426",
        "description": ".history.Syn_props_20250223162426",
        "peekOfCode": "coloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],\n    'Circularity': shape_metrics[1],",
        "detail": ".history.Syn_props_20250223162426",
        "documentation": {}
    },
    {
        "label": "morphology_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162426",
        "description": ".history.Syn_props_20250223162426",
        "peekOfCode": "morphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],\n    'Circularity': shape_metrics[1],\n    'Mean Intensity': intensity_metrics[0],",
        "detail": ".history.Syn_props_20250223162426",
        "documentation": {}
    },
    {
        "label": "metrics_dict",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162426",
        "description": ".history.Syn_props_20250223162426",
        "peekOfCode": "metrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],\n    'Circularity': shape_metrics[1],\n    'Mean Intensity': intensity_metrics[0],\n    'Median Intensity': intensity_metrics[1],\n    'Std Intensity': intensity_metrics[2],",
        "detail": ".history.Syn_props_20250223162426",
        "documentation": {}
    },
    {
        "label": "metrics_df",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162426",
        "description": ".history.Syn_props_20250223162426",
        "peekOfCode": "metrics_df = pd.DataFrame.from_dict(metrics_dict, orient='index', columns=['Value'])\n# Pretty print the DataFrame\nprint(\"Synapse Metrics:\")\nprint(metrics_df.to_string(index=True, header=False, float_format=lambda x: f\"{x:.2f}\"))\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223162426",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162441",
        "description": ".history.Syn_props_20250223162441",
        "peekOfCode": "path_ = 'data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223162441",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162441",
        "description": ".history.Syn_props_20250223162441",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223162441",
        "documentation": {}
    },
    {
        "label": "syn_id",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162441",
        "description": ".history.Syn_props_20250223162441",
        "peekOfCode": "syn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223162441",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162441",
        "description": ".history.Syn_props_20250223162441",
        "peekOfCode": "img = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)",
        "detail": ".history.Syn_props_20250223162441",
        "documentation": {}
    },
    {
        "label": "pre_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162441",
        "description": ".history.Syn_props_20250223162441",
        "peekOfCode": "pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics",
        "detail": ".history.Syn_props_20250223162441",
        "documentation": {}
    },
    {
        "label": "post_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162441",
        "description": ".history.Syn_props_20250223162441",
        "peekOfCode": "post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {",
        "detail": ".history.Syn_props_20250223162441",
        "documentation": {}
    },
    {
        "label": "size_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162441",
        "description": ".history.Syn_props_20250223162441",
        "peekOfCode": "size_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],",
        "detail": ".history.Syn_props_20250223162441",
        "documentation": {}
    },
    {
        "label": "shape_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162441",
        "description": ".history.Syn_props_20250223162441",
        "peekOfCode": "shape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],",
        "detail": ".history.Syn_props_20250223162441",
        "documentation": {}
    },
    {
        "label": "intensity_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162441",
        "description": ".history.Syn_props_20250223162441",
        "peekOfCode": "intensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],",
        "detail": ".history.Syn_props_20250223162441",
        "documentation": {}
    },
    {
        "label": "distance",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162441",
        "description": ".history.Syn_props_20250223162441",
        "peekOfCode": "distance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],",
        "detail": ".history.Syn_props_20250223162441",
        "documentation": {}
    },
    {
        "label": "coloc_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162441",
        "description": ".history.Syn_props_20250223162441",
        "peekOfCode": "coloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],\n    'Circularity': shape_metrics[1],",
        "detail": ".history.Syn_props_20250223162441",
        "documentation": {}
    },
    {
        "label": "morphology_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162441",
        "description": ".history.Syn_props_20250223162441",
        "peekOfCode": "morphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],\n    'Circularity': shape_metrics[1],\n    'Mean Intensity': intensity_metrics[0],",
        "detail": ".history.Syn_props_20250223162441",
        "documentation": {}
    },
    {
        "label": "metrics_dict",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162441",
        "description": ".history.Syn_props_20250223162441",
        "peekOfCode": "metrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],\n    'Circularity': shape_metrics[1],\n    'Mean Intensity': intensity_metrics[0],\n    'Median Intensity': intensity_metrics[1],\n    'Std Intensity': intensity_metrics[2],",
        "detail": ".history.Syn_props_20250223162441",
        "documentation": {}
    },
    {
        "label": "metrics_df",
        "kind": 5,
        "importPath": ".history.Syn_props_20250223162441",
        "description": ".history.Syn_props_20250223162441",
        "peekOfCode": "metrics_df = pd.DataFrame.from_dict(metrics_dict, orient='index', columns=['Value'])\n# Pretty print the DataFrame\nprint(\"Synapse Metrics:\")\nprint(metrics_df.to_string(index=True, header=False, float_format=lambda x: f\"{x:.2f}\"))\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_20250223162441",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223162440",
        "description": ".history.Syn_props_demo_20250223162440",
        "peekOfCode": "path_ = 'data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)",
        "detail": ".history.Syn_props_demo_20250223162440",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223162440",
        "description": ".history.Syn_props_demo_20250223162440",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nsynapses.head()\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)",
        "detail": ".history.Syn_props_demo_20250223162440",
        "documentation": {}
    },
    {
        "label": "syn_id",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223162440",
        "description": ".history.Syn_props_demo_20250223162440",
        "peekOfCode": "syn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)",
        "detail": ".history.Syn_props_demo_20250223162440",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223162440",
        "description": ".history.Syn_props_demo_20250223162440",
        "peekOfCode": "img = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)",
        "detail": ".history.Syn_props_demo_20250223162440",
        "documentation": {}
    },
    {
        "label": "pre_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223162440",
        "description": ".history.Syn_props_demo_20250223162440",
        "peekOfCode": "pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics",
        "detail": ".history.Syn_props_demo_20250223162440",
        "documentation": {}
    },
    {
        "label": "post_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223162440",
        "description": ".history.Syn_props_demo_20250223162440",
        "peekOfCode": "post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {",
        "detail": ".history.Syn_props_demo_20250223162440",
        "documentation": {}
    },
    {
        "label": "size_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223162440",
        "description": ".history.Syn_props_demo_20250223162440",
        "peekOfCode": "size_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],",
        "detail": ".history.Syn_props_demo_20250223162440",
        "documentation": {}
    },
    {
        "label": "shape_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223162440",
        "description": ".history.Syn_props_demo_20250223162440",
        "peekOfCode": "shape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],",
        "detail": ".history.Syn_props_demo_20250223162440",
        "documentation": {}
    },
    {
        "label": "intensity_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223162440",
        "description": ".history.Syn_props_demo_20250223162440",
        "peekOfCode": "intensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],",
        "detail": ".history.Syn_props_demo_20250223162440",
        "documentation": {}
    },
    {
        "label": "distance",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223162440",
        "description": ".history.Syn_props_demo_20250223162440",
        "peekOfCode": "distance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],",
        "detail": ".history.Syn_props_demo_20250223162440",
        "documentation": {}
    },
    {
        "label": "coloc_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223162440",
        "description": ".history.Syn_props_demo_20250223162440",
        "peekOfCode": "coloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],\n    'Circularity': shape_metrics[1],",
        "detail": ".history.Syn_props_demo_20250223162440",
        "documentation": {}
    },
    {
        "label": "morphology_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223162440",
        "description": ".history.Syn_props_demo_20250223162440",
        "peekOfCode": "morphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],\n    'Circularity': shape_metrics[1],\n    'Mean Intensity': intensity_metrics[0],",
        "detail": ".history.Syn_props_demo_20250223162440",
        "documentation": {}
    },
    {
        "label": "metrics_dict",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223162440",
        "description": ".history.Syn_props_demo_20250223162440",
        "peekOfCode": "metrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],\n    'Circularity': shape_metrics[1],\n    'Mean Intensity': intensity_metrics[0],\n    'Median Intensity': intensity_metrics[1],\n    'Std Intensity': intensity_metrics[2],",
        "detail": ".history.Syn_props_demo_20250223162440",
        "documentation": {}
    },
    {
        "label": "metrics_df",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223162440",
        "description": ".history.Syn_props_demo_20250223162440",
        "peekOfCode": "metrics_df = pd.DataFrame.from_dict(metrics_dict, orient='index', columns=['Value'])\n# Pretty print the DataFrame\nprint(\"Synapse Metrics:\")\nprint(metrics_df.to_string(index=True, header=False, float_format=lambda x: f\"{x:.2f}\"))\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_demo_20250223162440",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165840",
        "description": ".history.Syn_props_demo_20250223165840",
        "peekOfCode": "path_ = 'data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nprint(synapses.head())\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)",
        "detail": ".history.Syn_props_demo_20250223165840",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165840",
        "description": ".history.Syn_props_demo_20250223165840",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nprint(synapses.head())\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)",
        "detail": ".history.Syn_props_demo_20250223165840",
        "documentation": {}
    },
    {
        "label": "syn_id",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165840",
        "description": ".history.Syn_props_demo_20250223165840",
        "peekOfCode": "syn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)",
        "detail": ".history.Syn_props_demo_20250223165840",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165840",
        "description": ".history.Syn_props_demo_20250223165840",
        "peekOfCode": "img = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)",
        "detail": ".history.Syn_props_demo_20250223165840",
        "documentation": {}
    },
    {
        "label": "pre_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165840",
        "description": ".history.Syn_props_demo_20250223165840",
        "peekOfCode": "pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics",
        "detail": ".history.Syn_props_demo_20250223165840",
        "documentation": {}
    },
    {
        "label": "post_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165840",
        "description": ".history.Syn_props_demo_20250223165840",
        "peekOfCode": "post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {",
        "detail": ".history.Syn_props_demo_20250223165840",
        "documentation": {}
    },
    {
        "label": "size_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165840",
        "description": ".history.Syn_props_demo_20250223165840",
        "peekOfCode": "size_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],",
        "detail": ".history.Syn_props_demo_20250223165840",
        "documentation": {}
    },
    {
        "label": "shape_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165840",
        "description": ".history.Syn_props_demo_20250223165840",
        "peekOfCode": "shape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],",
        "detail": ".history.Syn_props_demo_20250223165840",
        "documentation": {}
    },
    {
        "label": "intensity_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165840",
        "description": ".history.Syn_props_demo_20250223165840",
        "peekOfCode": "intensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],",
        "detail": ".history.Syn_props_demo_20250223165840",
        "documentation": {}
    },
    {
        "label": "distance",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165840",
        "description": ".history.Syn_props_demo_20250223165840",
        "peekOfCode": "distance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],",
        "detail": ".history.Syn_props_demo_20250223165840",
        "documentation": {}
    },
    {
        "label": "coloc_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165840",
        "description": ".history.Syn_props_demo_20250223165840",
        "peekOfCode": "coloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],\n    'Circularity': shape_metrics[1],",
        "detail": ".history.Syn_props_demo_20250223165840",
        "documentation": {}
    },
    {
        "label": "morphology_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165840",
        "description": ".history.Syn_props_demo_20250223165840",
        "peekOfCode": "morphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],\n    'Circularity': shape_metrics[1],\n    'Mean Intensity': intensity_metrics[0],",
        "detail": ".history.Syn_props_demo_20250223165840",
        "documentation": {}
    },
    {
        "label": "metrics_dict",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165840",
        "description": ".history.Syn_props_demo_20250223165840",
        "peekOfCode": "metrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],\n    'Circularity': shape_metrics[1],\n    'Mean Intensity': intensity_metrics[0],\n    'Median Intensity': intensity_metrics[1],\n    'Std Intensity': intensity_metrics[2],",
        "detail": ".history.Syn_props_demo_20250223165840",
        "documentation": {}
    },
    {
        "label": "metrics_df",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165840",
        "description": ".history.Syn_props_demo_20250223165840",
        "peekOfCode": "metrics_df = pd.DataFrame.from_dict(metrics_dict, orient='index', columns=['Value'])\n# Pretty print the DataFrame\nprint(\"Synapse Metrics:\")\nprint(metrics_df.to_string(index=True, header=False, float_format=lambda x: f\"{x:.2f}\"))\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_demo_20250223165840",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165903",
        "description": ".history.Syn_props_demo_20250223165903",
        "peekOfCode": "path_ = 'data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nprint(synapses.columns)\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)",
        "detail": ".history.Syn_props_demo_20250223165903",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165903",
        "description": ".history.Syn_props_demo_20250223165903",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nprint(synapses.columns)\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)",
        "detail": ".history.Syn_props_demo_20250223165903",
        "documentation": {}
    },
    {
        "label": "syn_id",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165903",
        "description": ".history.Syn_props_demo_20250223165903",
        "peekOfCode": "syn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)",
        "detail": ".history.Syn_props_demo_20250223165903",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165903",
        "description": ".history.Syn_props_demo_20250223165903",
        "peekOfCode": "img = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)",
        "detail": ".history.Syn_props_demo_20250223165903",
        "documentation": {}
    },
    {
        "label": "pre_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165903",
        "description": ".history.Syn_props_demo_20250223165903",
        "peekOfCode": "pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics",
        "detail": ".history.Syn_props_demo_20250223165903",
        "documentation": {}
    },
    {
        "label": "post_mask",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165903",
        "description": ".history.Syn_props_demo_20250223165903",
        "peekOfCode": "post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {",
        "detail": ".history.Syn_props_demo_20250223165903",
        "documentation": {}
    },
    {
        "label": "size_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165903",
        "description": ".history.Syn_props_demo_20250223165903",
        "peekOfCode": "size_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],",
        "detail": ".history.Syn_props_demo_20250223165903",
        "documentation": {}
    },
    {
        "label": "shape_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165903",
        "description": ".history.Syn_props_demo_20250223165903",
        "peekOfCode": "shape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],",
        "detail": ".history.Syn_props_demo_20250223165903",
        "documentation": {}
    },
    {
        "label": "intensity_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165903",
        "description": ".history.Syn_props_demo_20250223165903",
        "peekOfCode": "intensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],",
        "detail": ".history.Syn_props_demo_20250223165903",
        "documentation": {}
    },
    {
        "label": "distance",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165903",
        "description": ".history.Syn_props_demo_20250223165903",
        "peekOfCode": "distance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],",
        "detail": ".history.Syn_props_demo_20250223165903",
        "documentation": {}
    },
    {
        "label": "coloc_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165903",
        "description": ".history.Syn_props_demo_20250223165903",
        "peekOfCode": "coloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],\n    'Circularity': shape_metrics[1],",
        "detail": ".history.Syn_props_demo_20250223165903",
        "documentation": {}
    },
    {
        "label": "morphology_metrics",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165903",
        "description": ".history.Syn_props_demo_20250223165903",
        "peekOfCode": "morphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],\n    'Circularity': shape_metrics[1],\n    'Mean Intensity': intensity_metrics[0],",
        "detail": ".history.Syn_props_demo_20250223165903",
        "documentation": {}
    },
    {
        "label": "metrics_dict",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165903",
        "description": ".history.Syn_props_demo_20250223165903",
        "peekOfCode": "metrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],\n    'Circularity': shape_metrics[1],\n    'Mean Intensity': intensity_metrics[0],\n    'Median Intensity': intensity_metrics[1],\n    'Std Intensity': intensity_metrics[2],",
        "detail": ".history.Syn_props_demo_20250223165903",
        "documentation": {}
    },
    {
        "label": "metrics_df",
        "kind": 5,
        "importPath": ".history.Syn_props_demo_20250223165903",
        "description": ".history.Syn_props_demo_20250223165903",
        "peekOfCode": "metrics_df = pd.DataFrame.from_dict(metrics_dict, orient='index', columns=['Value'])\n# Pretty print the DataFrame\nprint(\"Synapse Metrics:\")\nprint(metrics_df.to_string(index=True, header=False, float_format=lambda x: f\"{x:.2f}\"))\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": ".history.Syn_props_demo_20250223165903",
        "documentation": {}
    },
    {
        "label": "generate_points",
        "kind": 2,
        "importPath": "notebooks.randomsynapsetest",
        "description": "notebooks.randomsynapsetest",
        "peekOfCode": "def generate_points(n: int, mode: str, stick_length: float = 1.0) -> np.ndarray:\n    \"\"\"Generate points on a stick using different distribution patterns.\"\"\"\n    if mode == 'uniform':\n        return np.random.uniform(0, stick_length, n)\n    elif mode == 'two_bunches':\n        # Mix of two normal distributions centered at 0.25 and 0.75 of stick length\n        points = np.concatenate([\n            np.random.normal(0.25 * stick_length, 0.05 * stick_length, n//2),\n            np.random.normal(0.75 * stick_length, 0.05 * stick_length, n//2 + n%2)\n        ])",
        "detail": "notebooks.randomsynapsetest",
        "documentation": {}
    },
    {
        "label": "calculate_metrics",
        "kind": 2,
        "importPath": "notebooks.randomsynapsetest",
        "description": "notebooks.randomsynapsetest",
        "peekOfCode": "def calculate_metrics(points: np.ndarray) -> dict:\n    \"\"\"Calculate various distribution metrics.\"\"\"\n    # Sort points for nearest neighbor calculation\n    sorted_points = np.sort(points)\n    # Calculate nearest neighbor distances\n    nn_distances = np.diff(sorted_points)  # distances to next neighbor\n    # Calculate pairwise distances\n    pairwise_distances = np.abs(points[:, None] - points)\n    np.fill_diagonal(pairwise_distances, np.inf)  # exclude self-distances\n    min_distances = np.min(pairwise_distances, axis=1)  # minimum distance for each point",
        "detail": "notebooks.randomsynapsetest",
        "documentation": {}
    },
    {
        "label": "plot_experiment",
        "kind": 2,
        "importPath": "notebooks.randomsynapsetest",
        "description": "notebooks.randomsynapsetest",
        "peekOfCode": "def plot_experiment(ax: plt.Axes = None, points: np.ndarray = None, \n                   metrics: dict = None, title: str = '') -> plt.Axes:\n    \"\"\"Plot points and their distribution on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    # Plot points as dots\n    ax.scatter(points, np.ones_like(points) * 0.5, color='black', alpha=0.5, s=50)\n    # Add kernel density estimate\n    if len(points) > 1:\n        kde = gaussian_kde(points)",
        "detail": "notebooks.randomsynapsetest",
        "documentation": {}
    },
    {
        "label": "plot_metrics",
        "kind": 2,
        "importPath": "notebooks.randomsynapsetest",
        "description": "notebooks.randomsynapsetest",
        "peekOfCode": "def plot_metrics(ax: plt.Axes = None, metrics: dict = None, \n                title: str = '') -> plt.Axes:\n    \"\"\"Plot metrics as bar chart on given axes.\"\"\"\n    if ax is None:\n        _, ax = plt.subplots(1, 1, figsize=(8, 2))\n    x = np.arange(len(metrics))\n    ax.bar(x, list(metrics.values()))\n    ax.set_xticks(x)\n    ax.set_xticklabels(list(metrics.keys()), rotation=45)\n    ax.set_title(title)",
        "detail": "notebooks.randomsynapsetest",
        "documentation": {}
    },
    {
        "label": "run_experiments",
        "kind": 2,
        "importPath": "notebooks.randomsynapsetest",
        "description": "notebooks.randomsynapsetest",
        "peekOfCode": "def run_experiments():\n    \"\"\"Run all experiments and create visualization.\"\"\"\n    # Define base experiments (will be run with both stick lengths)\n    base_experiments = [\n        ('uniform', 100, 'Uniform'),\n        ('uniform', 1000, 'Uniform'),\n        ('two_bunches', 100, 'Two Bunches'),\n        ('two_bunches', 1000, 'Two Bunches'),\n        ('three_clusters', 100, 'Three Clusters'),\n        ('three_clusters', 1000, 'Three Clusters')",
        "detail": "notebooks.randomsynapsetest",
        "documentation": {}
    },
    {
        "label": "load_metrics",
        "kind": 2,
        "importPath": "metrics_analysis",
        "description": "metrics_analysis",
        "peekOfCode": "def load_metrics():\n    \"\"\"Load pre-calculated metrics from CSV\"\"\"\n    metrics_df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Select only numerical columns for clustering\n    feature_cols = metrics_df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    return metrics_df, feature_cols\ndef perform_clustering_analysis(metrics_df, feature_cols, n_clusters=3, method='pca'):\n    \"\"\"Perform dimensionality reduction and clustering on the metrics\"\"\"\n    X = metrics_df[feature_cols]",
        "detail": "metrics_analysis",
        "documentation": {}
    },
    {
        "label": "perform_clustering_analysis",
        "kind": 2,
        "importPath": "metrics_analysis",
        "description": "metrics_analysis",
        "peekOfCode": "def perform_clustering_analysis(metrics_df, feature_cols, n_clusters=3, method='pca'):\n    \"\"\"Perform dimensionality reduction and clustering on the metrics\"\"\"\n    X = metrics_df[feature_cols]\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    # Dimensionality reduction\n    if method == 'pca':\n        reducer = PCA(n_components=2)\n        X_reduced = reducer.fit_transform(X_scaled)\n        explained_var = reducer.explained_variance_ratio_",
        "detail": "metrics_analysis",
        "documentation": {}
    },
    {
        "label": "plot_clusters",
        "kind": 2,
        "importPath": "metrics_analysis",
        "description": "metrics_analysis",
        "peekOfCode": "def plot_clusters(X_reduced, clusters, variance_ratio=None, method='pca'):\n    \"\"\"Plot the clustering results\"\"\"\n    plt.figure(figsize=(10, 8))\n    scatter = plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=clusters, cmap='viridis')\n    if method == 'pca':\n        plt.xlabel(f'PC1 ({variance_ratio[0]:.2%} variance explained)')\n        plt.ylabel(f'PC2 ({variance_ratio[1]:.2%} variance explained)')\n        title = 'Synapse Clusters (PCA)'\n    else:\n        plt.xlabel('UMAP1')",
        "detail": "metrics_analysis",
        "documentation": {}
    },
    {
        "label": "perform_umap",
        "kind": 2,
        "importPath": "metrics_analysis",
        "description": "metrics_analysis",
        "peekOfCode": "def perform_umap(metrics_df, feature_cols):\n    \"\"\"Perform UMAP dimensionality reduction\"\"\"\n    X = metrics_df[feature_cols]\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X)\n    reducer = umap.UMAP(random_state=42)\n    X_reduced = reducer.fit_transform(X_scaled)\n    return X_reduced\ndef plot_cell_types(metrics_df, X_umap):\n    \"\"\"Plot UMAP colored by different cell type classifications\"\"\"",
        "detail": "metrics_analysis",
        "documentation": {}
    },
    {
        "label": "plot_cell_types",
        "kind": 2,
        "importPath": "metrics_analysis",
        "description": "metrics_analysis",
        "peekOfCode": "def plot_cell_types(metrics_df, X_umap):\n    \"\"\"Plot UMAP colored by different cell type classifications\"\"\"\n    fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n    # Define the subplots data\n    plots = [\n        ('pre_syn_cell_type', 'Pre-synaptic Cell Type', 0, 0),\n        ('pre_syn_clf_type', 'Pre-synaptic Classification', 0, 1),\n        ('post_syn_cell_type', 'Post-synaptic Cell Type', 1, 0),\n        ('post_syn_clf_type', 'Post-synaptic Classification', 1, 1)\n    ]",
        "detail": "metrics_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_size",
        "kind": 2,
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "peekOfCode": "def synapse_size(pre_mask, post_mask):\n    \"\"\"Calculate synapse size metrics.\"\"\"\n    synapse_mask = pre_mask | post_mask\n    synapse_area = np.sum(synapse_mask)\n    pre_area = np.sum(pre_mask)\n    post_area = np.sum(post_mask)\n    pre_post_ratio = pre_area / post_area\n    return synapse_area, pre_area, post_area, pre_post_ratio\ndef synapse_shape(pre_mask, post_mask):\n    \"\"\"Calculate synapse shape metrics.\"\"\"",
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_shape",
        "kind": 2,
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "peekOfCode": "def synapse_shape(pre_mask, post_mask):\n    \"\"\"Calculate synapse shape metrics.\"\"\"\n    synapse_mask = pre_mask | post_mask\n    perimeter = measure.perimeter(synapse_mask)\n    circularity = 4 * np.pi * np.sum(synapse_mask) / (perimeter ** 2)\n    return perimeter, circularity\ndef synapse_intensity(image, pre_mask, post_mask):\n    \"\"\"Calculate synapse intensity metrics.\"\"\"\n    synapse_mask = pre_mask | post_mask\n    synapse_intensities = image[synapse_mask]",
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_intensity",
        "kind": 2,
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "peekOfCode": "def synapse_intensity(image, pre_mask, post_mask):\n    \"\"\"Calculate synapse intensity metrics.\"\"\"\n    synapse_mask = pre_mask | post_mask\n    synapse_intensities = image[synapse_mask]\n    mean_intensity = np.mean(synapse_intensities)\n    median_intensity = np.median(synapse_intensities)\n    std_intensity = np.std(synapse_intensities)\n    return mean_intensity, median_intensity, std_intensity\ndef synapse_distance(pre_mask, post_mask):\n    \"\"\"Calculate distance between pre- and post-synaptic regions.\"\"\"",
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_distance",
        "kind": 2,
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "peekOfCode": "def synapse_distance(pre_mask, post_mask):\n    \"\"\"Calculate distance between pre- and post-synaptic regions.\"\"\"\n    pre_centroid = measure.centroid(pre_mask)\n    post_centroid = measure.centroid(post_mask)\n    distance = np.sqrt((pre_centroid[0] - post_centroid[0]) ** 2 +\n                       (pre_centroid[1] - post_centroid[1]) ** 2)\n    return distance\ndef synapse_colocalization(pre_mask, post_mask):\n    \"\"\"Calculate synapse co-localization metrics.\"\"\"\n    intersection = pre_mask & post_mask",
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_colocalization",
        "kind": 2,
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "peekOfCode": "def synapse_colocalization(pre_mask, post_mask):\n    \"\"\"Calculate synapse co-localization metrics.\"\"\"\n    intersection = pre_mask & post_mask\n    union = pre_mask | post_mask\n    jaccard_index = np.sum(intersection) / np.sum(union)\n    pre_overlap = np.sum(intersection) / np.sum(pre_mask)\n    post_overlap = np.sum(intersection) / np.sum(post_mask)\n    return jaccard_index, pre_overlap, post_overlap\ndef synapse_morphology(pre_mask, post_mask):\n    \"\"\"Calculate synapse morphology metrics.\"\"\"",
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "synapse_morphology",
        "kind": 2,
        "importPath": "synapse_analysis",
        "description": "synapse_analysis",
        "peekOfCode": "def synapse_morphology(pre_mask, post_mask):\n    \"\"\"Calculate synapse morphology metrics.\"\"\"\n    synapse_mask = pre_mask | post_mask\n    labeled_synapse = measure.label(synapse_mask)\n    properties = measure.regionprops(labeled_synapse)\n    if properties:\n        major_axis_length = properties[0].major_axis_length\n        minor_axis_length = properties[0].minor_axis_length\n    else:\n        major_axis_length = 0",
        "detail": "synapse_analysis",
        "documentation": {}
    },
    {
        "label": "load_and_prepare_data",
        "kind": 2,
        "importPath": "synapse_classification",
        "description": "synapse_classification",
        "peekOfCode": "def load_and_prepare_data():\n    \"\"\"Load data and prepare features/labels for E/I classification\"\"\"\n    df = pd.read_csv('data/synapse_data_with_metrics.csv')\n    # Print class distribution to understand imbalance\n    print(\"\\nClass distribution:\")\n    print(df['pre_syn_clf_type'].value_counts())\n    # Select numerical features for classification\n    feature_cols = df.select_dtypes(include=[np.number]).columns\n    feature_cols = feature_cols.drop(['syn_id']) if 'syn_id' in feature_cols else feature_cols\n    # Create E/I labels from cell types",
        "detail": "synapse_classification",
        "documentation": {}
    },
    {
        "label": "evaluate_classifiers",
        "kind": 2,
        "importPath": "synapse_classification",
        "description": "synapse_classification",
        "peekOfCode": "def evaluate_classifiers(X, y):\n    \"\"\"Evaluate classifiers on full dataset with balanced training\"\"\"\n    classifiers = {\n        'Random Forest': RandomForestClassifier(random_state=42, \n                                              n_estimators=500,\n                                              max_depth=10,\n                                              min_samples_leaf=5),\n        'SVM': SVC(random_state=42, \n                   kernel='rbf',\n                   C=10,",
        "detail": "synapse_classification",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": "synapse_classification",
        "description": "synapse_classification",
        "peekOfCode": "def plot_results(results, confusion_matrices):\n    \"\"\"Plot confusion matrices as fractions\"\"\"\n    n_classifiers = len(confusion_matrices)\n    fig, axes = plt.subplots(1, n_classifiers, figsize=(15, 5))\n    # Plot confusion matrices\n    labels = ['I', 'E']\n    for idx, (name, cm) in enumerate(confusion_matrices.items()):\n        sns.heatmap(cm, annot=True, fmt='.3f', cmap='Blues', ax=axes[idx],\n                   xticklabels=labels, yticklabels=labels, vmin=0, vmax=1)\n        axes[idx].set_title(f'{name}\\nAccuracy: {results[name]:.3f}')",
        "detail": "synapse_classification",
        "documentation": {}
    },
    {
        "label": "calculate_synapse_metrics",
        "kind": 2,
        "importPath": "synapse_metrics",
        "description": "synapse_metrics",
        "peekOfCode": "def calculate_synapse_metrics(synapses, path_):\n    metrics_data = []\n    for i, row in synapses.iterrows():\n        print(i)\n        syn_id = row['syn_id']\n        img = np.load(f'{path_}{syn_id}_syn.npy')\n        pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\n        post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n        size_metrics = synapse_size(pre_mask, post_mask)\n        shape_metrics = synapse_shape(pre_mask, post_mask)",
        "detail": "synapse_metrics",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": "synapse_metrics",
        "description": "synapse_metrics",
        "peekOfCode": "path_ = 'data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nmetrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": "synapse_metrics",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": "synapse_metrics",
        "description": "synapse_metrics",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nmetrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": "synapse_metrics",
        "documentation": {}
    },
    {
        "label": "metrics_df",
        "kind": 5,
        "importPath": "synapse_metrics",
        "description": "synapse_metrics",
        "peekOfCode": "metrics_df = calculate_synapse_metrics(synapses, path_)\n# Merge the metrics DataFrame with the original synapses DataFrame\nsynapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": "synapse_metrics",
        "documentation": {}
    },
    {
        "label": "synapses_with_metrics",
        "kind": 5,
        "importPath": "synapse_metrics",
        "description": "synapse_metrics",
        "peekOfCode": "synapses_with_metrics = pd.merge(synapses, metrics_df, on='syn_id')\n# Save the updated DataFrame to a new CSV file\nsynapses_with_metrics.to_csv(f'{path_}synapse_data_with_metrics.csv', index=False)",
        "detail": "synapse_metrics",
        "documentation": {}
    },
    {
        "label": "path_",
        "kind": 5,
        "importPath": "Syn_props_demo",
        "description": "Syn_props_demo",
        "peekOfCode": "path_ = 'data/synpase_raw_em/'\nsynapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nprint(synapses.columns)\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)",
        "detail": "Syn_props_demo",
        "documentation": {}
    },
    {
        "label": "synapses",
        "kind": 5,
        "importPath": "Syn_props_demo",
        "description": "Syn_props_demo",
        "peekOfCode": "synapses = pd.read_csv(f'{path_}synapse_data.csv', index_col=0)\nprint(len(synapses))\nprint(synapses.columns)\nsyn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)",
        "detail": "Syn_props_demo",
        "documentation": {}
    },
    {
        "label": "syn_id",
        "kind": 5,
        "importPath": "Syn_props_demo",
        "description": "Syn_props_demo",
        "peekOfCode": "syn_id = synapses.iloc[0].syn_id\nimg = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)",
        "detail": "Syn_props_demo",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": "Syn_props_demo",
        "description": "Syn_props_demo",
        "peekOfCode": "img = np.load(f'{path_}{syn_id}_syn.npy')\npre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)",
        "detail": "Syn_props_demo",
        "documentation": {}
    },
    {
        "label": "pre_mask",
        "kind": 5,
        "importPath": "Syn_props_demo",
        "description": "Syn_props_demo",
        "peekOfCode": "pre_mask = np.load(f'{path_}{syn_id}_pre_syn_n_mask.npy')\npost_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics",
        "detail": "Syn_props_demo",
        "documentation": {}
    },
    {
        "label": "post_mask",
        "kind": 5,
        "importPath": "Syn_props_demo",
        "description": "Syn_props_demo",
        "peekOfCode": "post_mask = np.load(f'{path_}{syn_id}_post_syn_n_mask.npy')\n# Calculate metrics for a single synapse\nsize_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {",
        "detail": "Syn_props_demo",
        "documentation": {}
    },
    {
        "label": "size_metrics",
        "kind": 5,
        "importPath": "Syn_props_demo",
        "description": "Syn_props_demo",
        "peekOfCode": "size_metrics = synapse_size(pre_mask, post_mask)\nshape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],",
        "detail": "Syn_props_demo",
        "documentation": {}
    },
    {
        "label": "shape_metrics",
        "kind": 5,
        "importPath": "Syn_props_demo",
        "description": "Syn_props_demo",
        "peekOfCode": "shape_metrics = synapse_shape(pre_mask, post_mask)\nintensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],",
        "detail": "Syn_props_demo",
        "documentation": {}
    },
    {
        "label": "intensity_metrics",
        "kind": 5,
        "importPath": "Syn_props_demo",
        "description": "Syn_props_demo",
        "peekOfCode": "intensity_metrics = synapse_intensity(img, pre_mask, post_mask)\ndistance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],",
        "detail": "Syn_props_demo",
        "documentation": {}
    },
    {
        "label": "distance",
        "kind": 5,
        "importPath": "Syn_props_demo",
        "description": "Syn_props_demo",
        "peekOfCode": "distance = synapse_distance(pre_mask, post_mask)\ncoloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],",
        "detail": "Syn_props_demo",
        "documentation": {}
    },
    {
        "label": "coloc_metrics",
        "kind": 5,
        "importPath": "Syn_props_demo",
        "description": "Syn_props_demo",
        "peekOfCode": "coloc_metrics = synapse_colocalization(pre_mask, post_mask)\nmorphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],\n    'Circularity': shape_metrics[1],",
        "detail": "Syn_props_demo",
        "documentation": {}
    },
    {
        "label": "morphology_metrics",
        "kind": 5,
        "importPath": "Syn_props_demo",
        "description": "Syn_props_demo",
        "peekOfCode": "morphology_metrics = synapse_morphology(pre_mask, post_mask)\n# Create a dictionary with the metrics\nmetrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],\n    'Circularity': shape_metrics[1],\n    'Mean Intensity': intensity_metrics[0],",
        "detail": "Syn_props_demo",
        "documentation": {}
    },
    {
        "label": "metrics_dict",
        "kind": 5,
        "importPath": "Syn_props_demo",
        "description": "Syn_props_demo",
        "peekOfCode": "metrics_dict = {\n    'Synapse Area': size_metrics[0],\n    'Pre-synaptic Area': size_metrics[1],\n    'Post-synaptic Area': size_metrics[2],\n    'Pre-Post Area Ratio': size_metrics[3],\n    'Perimeter': shape_metrics[0],\n    'Circularity': shape_metrics[1],\n    'Mean Intensity': intensity_metrics[0],\n    'Median Intensity': intensity_metrics[1],\n    'Std Intensity': intensity_metrics[2],",
        "detail": "Syn_props_demo",
        "documentation": {}
    },
    {
        "label": "metrics_df",
        "kind": 5,
        "importPath": "Syn_props_demo",
        "description": "Syn_props_demo",
        "peekOfCode": "metrics_df = pd.DataFrame.from_dict(metrics_dict, orient='index', columns=['Value'])\n# Pretty print the DataFrame\nprint(\"Synapse Metrics:\")\nprint(metrics_df.to_string(index=True, header=False, float_format=lambda x: f\"{x:.2f}\"))\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 6))\nax1.imshow(img.T, cmap='gray')\nax2.imshow(img.T, cmap='gray')\nax2.imshow(pre_mask.T, alpha=0.5)\nax2.imshow(post_mask.T, alpha=0.5)\nplt.tight_layout()",
        "detail": "Syn_props_demo",
        "documentation": {}
    }
]